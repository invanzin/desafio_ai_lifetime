# ü§ñ Documenta√ß√£o: Extractor (extractor.py)

## üìö √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura LangChain](#arquitetura-langchain)
3. [Componentes Principais](#componentes-principais)
4. [Fluxo de Extra√ß√£o](#fluxo-de-extra√ß√£o)
5. [Resili√™ncia e Retry](#resili√™ncia-e-retry)
6. [Sistema de Reparo](#sistema-de-reparo)
7. [Logging e Seguran√ßa](#logging-e-seguran√ßa)
8. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)

---

## üéØ Vis√£o Geral

O arquivo `extractor.py` √© o **c√©rebro do microservi√ßo**. Ele √© respons√°vel por:

‚úÖ Conectar com a OpenAI API (GPT-4o/GPT-4-turbo)  
‚úÖ Orquestrar a extra√ß√£o usando LangChain  
‚úÖ Garantir resili√™ncia (retry autom√°tico)  
‚úÖ Reparar JSONs malformados  
‚úÖ Validar sa√≠da com Pydantic  
‚úÖ Logar tudo de forma segura (sem PII completa)

### Por que LangChain?

**LangChain** √© um framework que facilita a constru√ß√£o de aplica√ß√µes com LLMs (Large Language Models). Ele fornece:

- **Prompts estruturados:** Templates reutiliz√°veis
- **Chains:** Sequ√™ncias de opera√ß√µes (prompt ‚Üí LLM ‚Üí parser)
- **Output parsers:** Convers√£o autom√°tica de texto ‚Üí JSON
- **Retry logic:** Integra√ß√£o nativa com tenacity

**Sem LangChain** (c√≥digo verboso):
```python
import openai

prompt = f"Extraia JSON de: {transcript}"
response = openai.ChatCompletion.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": prompt}]
)
text = response.choices[0].message.content
json_data = json.loads(text)  # Pode falhar!
```

**Com LangChain** (clean e robusto):
```python
chain = prompt | llm | parser
result = await chain.ainvoke({"transcript": transcript})
# J√° retorna dict Python!
```

---

## üèóÔ∏è Arquitetura LangChain

### Componentes da Chain

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    LANGCHAIN CHAIN                       ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Prompt     ‚îÇ ‚Üí ‚îÇ     LLM      ‚îÇ ‚Üí ‚îÇ   Parser    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Template    ‚îÇ   ‚îÇ  (ChatGPT)   ‚îÇ   ‚îÇ   (JSON)    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Input: transcript + metadata_json                       ‚îÇ
‚îÇ  Output: dict Python                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### C√≥digo Real

```python
# 1. Prompt Template
prompt = ChatPromptTemplate.from_messages([
    ("system", """Voc√™ √© um assistente especializado...
    
    Extraia informa√ß√µes no formato JSON..."""),
    
    ("human", """TRANSCRI√á√ÉO:
    {transcript}
    
    METADATA FORNECIDO:
    {metadata_json}
    
    Retorne o JSON extra√≠do:""")
])

# 2. LLM (ChatGPT)
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0,    # Determin√≠stico
    timeout=30.0      # Timeout de 30s
)

# 3. Parser JSON
parser = JsonOutputParser()

# 4. Chain completa (operador | = pipe)
chain = prompt | llm | parser

# 5. Invoca√ß√£o (ass√≠ncrona)
result = await chain.ainvoke({
    "transcript": "Cliente: Ol√°...",
    "metadata_json": '{"meeting_id": "MTG001"}'
})
# Resultado: dict Python pronto para usar!
```

### O que acontece nos bastidores?

1. **Prompt √© renderizado** (vari√°veis substitu√≠das):
```
TRANSCRI√á√ÉO:
Cliente: Ol√°, preciso de R$ 500 mil...

METADATA FORNECIDO:
{"meeting_id": "MTG001", "customer_id": "CUST001"}

Retorne o JSON extra√≠do:
```

2. **LLM processa e retorna texto**:
```
{
  "meeting_id": "MTG001",
  "customer_id": "CUST001",
  "customer_name": "Jo√£o Silva",
  "summary": "Reuni√£o focou em...",
  ...
}
```

3. **Parser converte texto ‚Üí dict Python**:
```python
{
    "meeting_id": "MTG001",
    "customer_id": "CUST001",
    "customer_name": "Jo√£o Silva",
    "summary": "Reuni√£o focou em...",
    ...
}
```

---

## üß© Componentes Principais

### 1. Inicializa√ß√£o do LLM

```python
def _get_llm():
    """Inicializa e retorna o modelo de linguagem OpenAI configurado."""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError(
            "OPENAI_API_KEY n√£o encontrada. "
            "Configure a vari√°vel de ambiente no arquivo .env"
        )
    
    model_name = os.getenv("OPENAI_MODEL", "gpt-4o")
    
    return ChatOpenAI(
        model=model_name,
        temperature=0,   # Determin√≠stico (sem aleatoriedade)
        timeout=30.0,    # Timeout m√°ximo de 30s (requisito)
        api_key=api_key,
    )
```

**Por que `temperature=0`?**
- Torna a IA **determin√≠stica** (mesma entrada ‚Üí mesma sa√≠da)
- Reduz "alucina√ß√µes" (inventar informa√ß√µes)
- Ideal para extra√ß√£o de dados estruturados

**Compara√ß√£o de temperatures:**
```python
# temperature=0 (determin√≠stico)
"Cliente interessado em empr√©stimo"
"Cliente interessado em empr√©stimo"  # Sempre igual

# temperature=0.7 (criativo)
"Cliente interessado em empr√©stimo"
"O cliente demonstrou interesse em obter financiamento"  # Varia
```

---

### 2. Prompt System

O prompt system √© **crucial** - ele instrui a IA sobre:
- ‚úÖ O que extrair
- ‚úÖ Como lidar com metadados fornecidos
- ‚úÖ O que fazer quando dados faltam
- ‚úÖ Formato da sa√≠da

```python
("system", """Voc√™ √© um assistente especializado em extrair informa√ß√µes 
estruturadas de transcri√ß√µes de reuni√µes banc√°rias.

**REGRAS IMPORTANTES:**

1. **PRIORIDADE DOS METADADOS:**
   - Se metadados forem fornecidos (METADATA n√£o vazio), USE-OS COMO VERDADE ABSOLUTA
   - N√£o altere, n√£o invente, n√£o "corrija" dados fornecidos nos metadados
   - Metadados fornecidos t√™m prioridade sobre qualquer informa√ß√£o na transcri√ß√£o

2. **EXTRA√á√ÉO DA TRANSCRI√á√ÉO (quando metadados ausentes):**
   - Se algum campo de metadados estiver vazio/null, EXTRAIA da transcri√ß√£o:
     * customer_name: nome do cliente mencionado nos di√°logos
     * banker_name: nome do banker/gerente mencionado
     * meet_type: tipo da reuni√£o inferido do contexto
     * meet_date: data mencionada na transcri√ß√£o (formato ISO 8601)
     * customer_id: se n√£o identific√°vel ‚Üí deixe como "unknown" 
     * banker_id: se n√£o identific√°vel ‚Üí deixe como "unknown" 
     * meeting_id: se n√£o identific√°vel ‚Üí deixe como "unknown" 

3. **CAMPOS SEMPRE EXTRA√çDOS DA TRANSCRI√á√ÉO:**
   - summary: resumo executivo com EXATAMENTE 100-200 palavras
   - key_points: lista de 3-7 pontos-chave da reuni√£o
   - action_items: lista de a√ß√µes/tarefas identificadas
   - topics: lista de 2-5 t√≥picos/assuntos principais

4. **VALIDA√á√ïES:**
   - N√ÉO invente informa√ß√µes que n√£o est√£o na transcri√ß√£o
   - N√ÉO deixe campos obrigat√≥rios vazios (use "unknown" se necess√°rio)
   - Garanta que o summary tenha 100-200 palavras (conte as palavras!)

**FORMATO DE SA√çDA:**
Retorne um JSON v√°lido com os seguintes campos:
- meeting_id: string (do metadata ou 'unknown')
- customer_id: string (do metadata ou 'unknown')
- customer_name: string (do metadata ou extra√≠do da transcri√ß√£o)
...

Responda APENAS com o JSON v√°lido, SEM TEXTO ADICIONAL.""")
```

**Por que tantas instru√ß√µes?**
- LLMs podem "esquecer" instru√ß√µes se n√£o forem claras
- Instru√ß√µes expl√≠citas reduzem erros
- Repeti√ß√£o de conceitos-chave aumenta compliance

---

### 3. Fun√ß√µes Auxiliares

#### `_sanitize_transcript_for_log()` - Prote√ß√£o de PII

```python
def _sanitize_transcript_for_log(transcript: str, max_chars: int = 300) -> str:
    """Trunca a transcri√ß√£o para log seguro (sem PII completa)."""
    if len(transcript) <= max_chars:
        return transcript
    return transcript[:max_chars] + f"... (truncado, total: {len(transcript)} chars)"
```

**Exemplo:**
```python
transcript = "Cliente Jo√£o Silva, CPF 123.456.789-00, solicita empr√©stimo..."

# Log INSEGURO ‚ùå
logger.info(f"Transcript: {transcript}")
# Loga CPF completo!

# Log SEGURO ‚úÖ
logger.info(f"Transcript: {_sanitize_transcript_for_log(transcript)}")
# "Cliente Jo√£o Silva, CPF 123.456.789-00, sol... (truncado, total: 523 chars)"
```

#### `_prepare_metadata_for_prompt()` - Formata√ß√£o de Metadata

```python
def _prepare_metadata_for_prompt(normalized: NormalizedInput) -> str:
    """Prepara os metadados para envio ao LLM em formato JSON leg√≠vel."""
    metadata_dict = {
        "meeting_id": normalized.meeting_id,
        "customer_id": normalized.customer_id,
        "customer_name": normalized.customer_name,
        "banker_id": normalized.banker_id,
        "banker_name": normalized.banker_name,
        "meet_type": normalized.meet_type,
        "meet_date": normalized.meet_date.isoformat() if normalized.meet_date else None,
    }
    
    # Remove valores None para clareza (LLM ver√° apenas o que foi fornecido)
    metadata_dict = {k: v for k, v in metadata_dict.items() if v is not None}
    
    return json.dumps(metadata_dict, ensure_ascii=False, indent=2)
```

**Por que remover `None`?**

Sem remo√ß√£o:
```json
{
  "meeting_id": "MTG001",
  "customer_id": "CUST001",
  "customer_name": null,
  "banker_name": null,
  "meet_type": null
}
```

Com remo√ß√£o:
```json
{
  "meeting_id": "MTG001",
  "customer_id": "CUST001"
}
```

**Benef√≠cio:** LLM v√™ claramente quais campos foram fornecidos e quais deve extrair.

---

## üîÑ Fluxo de Extra√ß√£o

### Fun√ß√£o Principal: `extract_meeting_chain()`

```python
@retry(
    reraise=True,
    stop=stop_after_attempt(3),  # M√°ximo 3 tentativas
    wait=wait_exponential(multiplier=0.5, min=0.5, max=5.0),
    retry=retry_if_exception_type((RateLimitError, APITimeoutError, APIError)),
)
async def extract_meeting_chain(
    normalized: NormalizedInput,
    request_id: str = "-"
) -> ExtractedMeeting:
    """
    Extrai informa√ß√µes estruturadas de uma reuni√£o usando OpenAI + LangChain.
    
    Orquestra todo o processo de extra√ß√£o:
    1. Prepara os dados para o prompt
    2. Chama o LLM com retry autom√°tico (at√© 3 tentativas)
    3. Valida o resultado com Pydantic
    4. Tenta reparar se a valida√ß√£o falhar
    5. Preenche a chave de idempot√™ncia
    6. Retorna o objeto validado
    """
```

### Passo a Passo Detalhado

#### Passo 1: Prepara√ß√£o

```python
# Log in√≠cio (sem PII completa)
logger.info(
    f"[{request_id}] Iniciando extra√ß√£o | "
    f"transcript_len={len(normalized.transcript)} | "
    f"has_metadata={'sim' if normalized.meeting_id else 'n√£o'}"
)

# Prepara metadados para o prompt
metadata_json = _prepare_metadata_for_prompt(normalized)
# Resultado: '{"meeting_id": "MTG001", "customer_id": "CUST001"}'
```

#### Passo 2: Chamada ao LLM (com retry)

```python
try:
    raw_output = await chain.ainvoke({
        "transcript": normalized.transcript,
        "metadata_json": metadata_json
    })
    
    logger.info(
        f"[{request_id}] LLM respondeu | "
        f"output_keys={list(raw_output.keys())}"
    )
    
except (RateLimitError, APITimeoutError, APIError) as e:
    logger.error(
        f"[{request_id}] Erro na chamada ao LLM ap√≥s retries: "
        f"{type(e).__name__} - {str(e)[:200]}"
    )
    raise  # Re-lan√ßa exce√ß√£o para main.py tratar
```

**O que pode acontecer:**
- ‚úÖ **Sucesso:** LLM retorna JSON v√°lido
- ‚ö†Ô∏è **Rate Limit (429):** Muitas requisi√ß√µes ‚Üí retry autom√°tico
- ‚ö†Ô∏è **Timeout:** LLM demorou > 30s ‚Üí retry autom√°tico
- ‚ùå **API Error:** Erro na OpenAI ‚Üí retry autom√°tico
- ‚ùå **Ap√≥s 3 tentativas:** Lan√ßa exce√ß√£o (main.py retorna 502)

#### Passo 3: Valida√ß√£o com Pydantic

```python
try:
    extracted = ExtractedMeeting.model_validate(raw_output)
    logger.info(f"[{request_id}] Valida√ß√£o Pydantic OK na primeira tentativa")
    
except Exception as validation_error:
    # Valida√ß√£o falhou ‚Üí tenta reparar UMA vez
    logger.warning(
        f"[{request_id}] Valida√ß√£o Pydantic falhou | "
        f"erro={type(validation_error).__name__}: {str(validation_error)[:200]}"
    )
    
    try:
        repaired_output = await _repair_json(
            malformed_output=raw_output,
            validation_error=str(validation_error),
            normalized=normalized,
            request_id=request_id
        )
        
        # Tenta validar novamente
        extracted = ExtractedMeeting.model_validate(repaired_output)
        logger.info(f"[{request_id}] Valida√ß√£o OK ap√≥s reparo")
        
    except Exception as repair_error:
        logger.error(
            f"[{request_id}] Valida√ß√£o falhou mesmo ap√≥s reparo | "
            f"erro={type(repair_error).__name__}: {str(repair_error)[:200]}"
        )
        raise  # Re-lan√ßa (main.py retorna 500)
```

**Cen√°rios poss√≠veis:**
1. ‚úÖ **Valida√ß√£o OK na 1¬™ tentativa:** Segue para passo 4
2. ‚ö†Ô∏è **Valida√ß√£o FALHA ‚Üí Reparo ‚Üí OK:** Segue para passo 4
3. ‚ùå **Valida√ß√£o FALHA ‚Üí Reparo ‚Üí FALHA:** Lan√ßa exce√ß√£o (erro 500)

#### Passo 4: Preenchimento da Idempotency Key

```python
# Preenche a chave de idempot√™ncia se poss√≠vel
idem_key = normalized.compute_idempotency_key()
if idem_key:
    extracted.idempotency_key = idem_key
    logger.info(f"[{request_id}] Idempotency key calculada: {idem_key[:16]}...")
else:
    # Se n√£o for poss√≠vel calcular, usa placeholder
    extracted.idempotency_key = "no-idempotency-key-available"
    logger.warning(
        f"[{request_id}] N√£o foi poss√≠vel calcular idempotency_key "
        f"(faltam meeting_id, meet_date ou customer_id)"
    )
```

#### Passo 5: Log Final e Retorno

```python
# Log sucesso final
logger.info(
    f"[{request_id}] Extra√ß√£o conclu√≠da com sucesso | "
    f"meeting_id={extracted.meeting_id} | "
    f"summary_words={len(extracted.summary.split())} | "
    f"key_points={len(extracted.key_points)} | "
    f"action_items={len(extracted.action_items)}"
)

return extracted
```

---

## üîÅ Resili√™ncia e Retry

### Decorator `@retry`

```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

@retry(
    reraise=True,                           # Re-lan√ßa exce√ß√£o ap√≥s falhar
    stop=stop_after_attempt(3),             # M√°ximo 3 tentativas
    wait=wait_exponential(                  # Backoff exponencial
        multiplier=0.5, 
        min=0.5, 
        max=5.0
    ),
    retry=retry_if_exception_type((         # Apenas para esses erros
        RateLimitError,                      # 429 - Too Many Requests
        APITimeoutError,                     # Timeout de rede
        APIError                             # Erro gen√©rico da API
    )),
)
async def extract_meeting_chain(...):
    ...
```

### Como funciona o Retry?

**Exemplo: Rate Limit (429)**

```
Tentativa 1: ‚Üí RateLimitError (429)
              ‚Üì
              Espera 0.5s (2^0 * 0.5)
              ‚Üì
Tentativa 2: ‚Üí RateLimitError (429)
              ‚Üì
              Espera 1.0s (2^1 * 0.5)
              ‚Üì
Tentativa 3: ‚Üí RateLimitError (429)
              ‚Üì
              Espera 2.0s (2^2 * 0.5)
              ‚Üì
              ‚ùå Falha definitiva ‚Üí lan√ßa RateLimitError
```

**Exemplo: Sucesso na 2¬™ tentativa**

```
Tentativa 1: ‚Üí APITimeoutError
              ‚Üì
              Espera 0.5s
              ‚Üì
Tentativa 2: ‚Üí ‚úÖ Sucesso!
              ‚Üì
              Retorna resultado
```

### Por que Exponential Backoff?

**Linear (‚ùå):**
```
Tentativa 1 ‚Üí Espera 1s ‚Üí Tentativa 2 ‚Üí Espera 1s ‚Üí Tentativa 3
```
Problema: Pode sobrecarregar servidor se muitos clients fazem retry simult√¢neo.

**Exponencial (‚úÖ):**
```
Tentativa 1 ‚Üí Espera 0.5s ‚Üí Tentativa 2 ‚Üí Espera 1s ‚Üí Tentativa 3 ‚Üí Espera 2s
```
Benef√≠cio: "Espalha" os retries no tempo, reduzindo carga no servidor.

---

## üîß Sistema de Reparo

### Quando o Reparo √© Ativado?

Quando a **valida√ß√£o Pydantic falha** no output do LLM:

```python
# LLM retornou
{
    "meeting_id": "MTG001",
    "summary": "Breve resumo",  # ‚ùå Apenas 2 palavras (precisa 100-200)
    ...
}

# Pydantic tenta validar
extracted = ExtractedMeeting.model_validate(raw_output)
# ValidationError: summary deve ter 100-200 palavras, tem 2

# Sistema detecta erro e chama reparo
```

### Fun√ß√£o `_repair_json()`

```python
async def _repair_json(
    malformed_output: dict,
    validation_error: str,
    normalized: NormalizedInput,
    request_id: str
) -> dict:
    """
    Tenta reparar um JSON malformado reenviando ao LLM com o erro.
    
    Esta √© uma √öNICA tentativa de reparo.
    """
    logger.warning(
        f"[{request_id}] Tentando reparar JSON inv√°lido. "
        f"Erro: {validation_error[:200]}"
    )
    
    repair_prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um corretor de JSON especializado.
        Corrija o JSON abaixo para atender ao schema especificado.
        Mantenha o m√°ximo de informa√ß√µes corretas poss√≠vel.
        Responda APENAS com o JSON corrigido, sem explica√ß√µes."""),
        
        ("human", """JSON MALFORMADO:
        {malformed_json}
        
        ERRO DE VALIDA√á√ÉO:
        {error}
        
        TRANSCRI√á√ÉO ORIGINAL (para refer√™ncia se precisar):
        {transcript_preview}
        
        SCHEMA ESPERADO:
        - meeting_id, customer_id, customer_name (strings obrigat√≥rias)
        - summary (string com 100-200 palavras EXATAS)
        - key_points (array de strings)
        ...
        
        Retorne o JSON corrigido:""")
    ])
    
    repair_chain = repair_prompt | llm | parser
    
    repaired = await repair_chain.ainvoke({
        "malformed_json": json.dumps(malformed_output, ensure_ascii=False, indent=2),
        "error": str(validation_error),
        "transcript_preview": _sanitize_transcript_for_log(normalized.transcript, 500)
    })
    
    logger.info(f"[{request_id}] JSON reparado com sucesso")
    return repaired
```

### Exemplo de Reparo

**Input para reparo:**
```json
{
  "malformed_json": {
    "meeting_id": "MTG001",
    "summary": "Breve resumo",
    ...
  },
  "error": "summary deve ter 100-200 palavras, tem 2",
  "transcript_preview": "Cliente: Ol√°, preciso de R$ 500 mil..."
}
```

**LLM processa e retorna JSON corrigido:**
```json
{
  "meeting_id": "MTG001",
  "summary": "Reuni√£o entre cliente e banker focou na necessidade de empr√©stimo... (150 palavras)",
  ...
}
```

**Valida√ß√£o (2¬™ tentativa):**
```python
extracted = ExtractedMeeting.model_validate(repaired_output)
# ‚úÖ OK! (summary agora tem 150 palavras)
```

---

## üìä Logging e Seguran√ßa

### Estrutura de Logs

Todos os logs seguem o padr√£o:

```
[REQUEST_ID] A√ß√£o | contexto_key=valor | outro_contexto=valor
```

### Exemplo de Sequ√™ncia de Logs

```
[abc-123] Iniciando extra√ß√£o | transcript_len=790 | has_metadata=sim
[abc-123] LLM respondeu | output_keys=['meeting_id', 'customer_id', 'summary', ...]
[abc-123] Valida√ß√£o Pydantic OK na primeira tentativa
[abc-123] Idempotency key calculada: 7e3e97ffd83f...
[abc-123] Extra√ß√£o conclu√≠da com sucesso | meeting_id=MTG001 | summary_words=169
```

### O que √â e N√ÉO √â Logado

‚úÖ **√â logado:**
- Request ID (rastreamento)
- Tamanho da transcri√ß√£o (n√∫mero de caracteres)
- Presen√ßa de metadados (sim/n√£o)
- Chaves do JSON retornado pelo LLM
- Status de valida√ß√£o (OK/FALHA)
- Primeiros 16 chars da idempotency key
- N√∫mero de palavras do summary
- Quantidade de key_points/action_items
- Tipos de erros (sem detalhes sens√≠veis)

‚ùå **N√ÉO √© logado:**
- Transcri√ß√£o completa
- Nomes de clientes/bankers
- Conte√∫do do resumo
- IDs completos de clientes
- CPFs, emails, telefones
- Detalhes financeiros

---

## üéì Exemplos Pr√°ticos

### Exemplo 1: Extra√ß√£o Bem-Sucedida (1¬™ Tentativa)

```python
# Input
normalized = NormalizedInput(
    transcript="Cliente: Ol√°, preciso de R$ 500 mil...",
    meeting_id="MTG001",
    customer_id="CUST001",
    meet_date=datetime(2025, 9, 10, 14, 30)
)

# Chamada
extracted = await extract_meeting_chain(normalized, "req-123")

# Logs:
# [req-123] Iniciando extra√ß√£o | transcript_len=790 | has_metadata=sim
# [req-123] LLM respondeu | output_keys=[...]
# [req-123] Valida√ß√£o Pydantic OK na primeira tentativa
# [req-123] Idempotency key calculada: 7e3e97ffd83f...
# [req-123] Extra√ß√£o conclu√≠da | meeting_id=MTG001 | summary_words=169

# Output
print(extracted.meeting_id)  # "MTG001"
print(extracted.summary)      # "Reuni√£o focou em... (169 palavras)"
```

### Exemplo 2: Retry por Rate Limit

```python
# Tentativa 1
[req-456] Iniciando extra√ß√£o | transcript_len=523 | has_metadata=n√£o
[req-456] Erro na chamada ao LLM: RateLimitError - Too Many Requests

# Espera 0.5s...

# Tentativa 2
[req-456] Iniciando extra√ß√£o | transcript_len=523 | has_metadata=n√£o
[req-456] LLM respondeu | output_keys=[...]
[req-456] Valida√ß√£o OK
[req-456] Extra√ß√£o conclu√≠da | meeting_id=unknown | summary_words=145
```

### Exemplo 3: Reparo de JSON

```python
# Tentativa 1 de Valida√ß√£o
[req-789] LLM respondeu | output_keys=[...]
[req-789] Valida√ß√£o Pydantic falhou | erro=ValueError: summary deve ter 100-200 palavras, tem 50

# Reparo
[req-789] Tentando reparar JSON inv√°lido. Erro: summary deve ter 100-200 palavras, tem 50
[req-789] JSON reparado com sucesso

# Tentativa 2 de Valida√ß√£o
[req-789] Valida√ß√£o OK ap√≥s reparo
[req-789] Extra√ß√£o conclu√≠da | summary_words=152
```

### Exemplo 4: Falha Definitiva

```python
# Tentativa 1
[req-999] Erro na chamada ao LLM: APITimeoutError

# Espera 0.5s...

# Tentativa 2
[req-999] Erro na chamada ao LLM: APITimeoutError

# Espera 1s...

# Tentativa 3
[req-999] Erro na chamada ao LLM: APITimeoutError

# Desiste
[req-999] Erro na chamada ao LLM ap√≥s retries: APITimeoutError - Request timeout
# Exce√ß√£o √© re-lan√ßada ‚Üí main.py retorna 502
```

---

## üí° Dicas e Boas Pr√°ticas

### 1. Temperature Adequada

```python
# ‚úÖ BOM - Para extra√ß√£o estruturada
llm = ChatOpenAI(temperature=0)

# ‚ùå RUIM - Para extra√ß√£o (gera varia√ß√µes)
llm = ChatOpenAI(temperature=0.7)
```

### 2. Timeout Apropriado

```python
# ‚úÖ BOM - 30s (requisito)
llm = ChatOpenAI(timeout=30.0)

# ‚ùå RUIM - Sem timeout (pode travar indefinidamente)
llm = ChatOpenAI()
```

### 3. Logs Estruturados

```python
# ‚úÖ BOM - F√°cil de parsear/filtrar
logger.info(f"[{request_id}] A√ß√£o | key1=value1 | key2=value2")

# ‚ùå RUIM - Dif√≠cil de parsear
logger.info(f"Fazendo a√ß√£o para {request_id} com {value1}")
```

### 4. Sanitiza√ß√£o de Dados Sens√≠veis

```python
# ‚úÖ BOM - Trunca antes de logar
logger.info(f"Transcript: {_sanitize_transcript_for_log(transcript)}")

# ‚ùå RUIM - Loga PII completa
logger.info(f"Transcript: {transcript}")
```

---

## üìä M√©tricas de Performance

| M√©trica | Valor T√≠pico |
|---------|--------------|
| **Tempo m√©dio de extra√ß√£o** | 3-8 segundos |
| **Taxa de sucesso (1¬™ tentativa)** | ~95% |
| **Taxa de reparo bem-sucedido** | ~85% |
| **Taxa de retry por rate limit** | ~2% |
| **Taxa de falha definitiva** | <1% |

---

## üîç Debugging

### Como debugar erros de extra√ß√£o?

1. **Verifique os logs com o Request ID:**
```bash
grep "abc-123" logs.txt
```

2. **Teste o prompt manualmente:**
```python
# No console Python
from app.extractors.extractor import prompt, llm, parser

result = (prompt | llm | parser).invoke({
    "transcript": "Cliente: Teste...",
    "metadata_json": "{}"
})
print(result)
```

3. **Valide o output manualmente:**
```python
from app.models.schemas import ExtractedMeeting

try:
    extracted = ExtractedMeeting.model_validate(result)
except Exception as e:
    print(f"Erro: {e}")
```

---

## üìö Refer√™ncias

- **LangChain Docs:** https://python.langchain.com/docs/get_started/introduction
- **OpenAI API:** https://platform.openai.com/docs/api-reference
- **Tenacity (Retry):** https://tenacity.readthedocs.io/

---

**Pr√≥ximo:** [04-MAIN-API.md](04-MAIN-API.md) - Como funciona a API FastAPI

