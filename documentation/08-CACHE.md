# 08 - Sistema de Cache de Idempot√™ncia

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Motiva√ß√£o e Benef√≠cios](#motiva√ß√£o-e-benef√≠cios)
3. [Arquitetura do Cache](#arquitetura-do-cache)
4. [Fun√ß√µes Principais](#fun√ß√µes-principais)
5. [Integra√ß√£o nos Endpoints](#integra√ß√£o-nos-endpoints)
6. [Fluxo de Requisi√ß√µes](#fluxo-de-requisi√ß√µes)
7. [Logs e Monitoramento](#logs-e-monitoramento)
8. [Configura√ß√£o](#configura√ß√£o)
9. [Testes](#testes)
10. [Pr√≥ximo N√≠vel: Redis](#pr√≥ximo-n√≠vel-redis)

---

## Vis√£o Geral

O **Sistema de Cache de Idempot√™ncia** implementa um mecanismo de cache em mem√≥ria que garante que requisi√ß√µes id√™nticas (mesma transcri√ß√£o, mesmo cliente, mesma reuni√£o) **n√£o sejam processadas m√∫ltiplas vezes** pela OpenAI API.

### Conceitos-Chave

- **Idempot√™ncia**: Garantia de que requisi√ß√µes id√™nticas produzem resultados id√™nticos
- **Cache em Mem√≥ria**: Armazenamento tempor√°rio de resultados usando um dicion√°rio Python
- **TTL (Time-To-Live)**: Tempo de validade do cache (padr√£o: 24 horas)
- **Idempotency Key**: SHA-256 hash gerado a partir de `meeting_id + meet_date + customer_id`

### Status da Implementa√ß√£o

```
‚úÖ Cache em mem√≥ria implementado
‚úÖ Integrado em /extract e /analyze
‚úÖ Logs estruturados
‚úÖ Configur√°vel via env var
‚úÖ Testado e validado
‚è≥ Redis (pr√≥ximo n√≠vel - opcional)
```

---

## Motiva√ß√£o e Benef√≠cios

### üéØ **Por Que Implementar Cache?**

1. **üí∞ Economia de Custos**
   - OpenAI API cobra por token processado
   - GPT-4o: ~$2.50 entrada + $10.00 sa√≠da por 1M tokens
   - Cache evita reprocessamento = economia direta

2. **‚ö° Performance**
   - Cache HIT: ~5ms (instant√¢neo)
   - Cache MISS: ~5-10s (processamento OpenAI)
   - **Speedup de 1000x** em cache hits

3. **üîí Idempot√™ncia Garantida**
   - Mesma requisi√ß√£o ‚Üí mesmo resultado
   - Importante para integra√ß√µes e retries
   - Compliance com APIs REST

4. **üìà Escalabilidade**
   - Reduz carga na OpenAI API
   - Permite mais requisi√ß√µes simult√¢neas
   - Melhor uso de rate limits

### üìä **Exemplo de Economia Real**

```
Cen√°rio: 1000 requisi√ß√µes/dia com 30% de duplicatas

SEM CACHE:
- 1000 chamadas OpenAI
- Custo: ~$0.05-0.10 por chamada
- Total: $50-100/dia = $1.500-3.000/m√™s

COM CACHE:
- 700 chamadas OpenAI (30% cache hit)
- Custo: ~$0.05-0.10 por chamada
- Total: $35-70/dia = $1.050-2.100/m√™s
- üí∞ ECONOMIA: $450-900/m√™s (30%)
```

---

## Arquitetura do Cache

### Estrutura de Dados

```python
# Cache global em mem√≥ria (dicion√°rio Python)
_cache: Dict[str, Tuple[dict, datetime]] = {}

# Formato:
# {
#   "1294cd73c1b883ca...": (
#       {...resultado_extra√≠do...},    # Dict com ExtractedMeeting ou AnalyzedMeeting
#       datetime(2025, 10, 15, 10, 30)  # Timestamp de quando foi salvo
#   )
# }
```

### Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SISTEMA DE CACHE                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  1. _cache: Dict[str, Tuple[dict, datetime]]               ‚îÇ
‚îÇ     ‚îî‚îÄ> Armazena: {idempotency_key: (result, timestamp)}  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  2. CACHE_TTL_HOURS: int (padr√£o: 24h)                     ‚îÇ
‚îÇ     ‚îî‚îÄ> Configur√°vel via CACHE_TTL_HOURS env var          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  3. Fun√ß√µes:                                                ‚îÇ
‚îÇ     ‚îú‚îÄ> get_from_cache(key) ‚Üí Optional[dict]              ‚îÇ
‚îÇ     ‚îú‚îÄ> save_to_cache(key, result) ‚Üí None                 ‚îÇ
‚îÇ     ‚îî‚îÄ> clear_cache() ‚Üí int                                ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Ciclo de Vida do Cache

```mermaid
flowchart TB
    Start([Requisi√ß√£o Chega]) --> Normalize[Normaliza Input]
    Normalize --> CalcKey[Calcula idempotency_key<br/>SHA-256]
    CalcKey --> HasKey{Key v√°lido?}
    
    HasKey -->|N√£o| Process[Processa com OpenAI<br/>SEM usar cache]
    HasKey -->|Sim| CheckCache{Existe no<br/>cache?}
    
    CheckCache -->|N√£o| Process
    CheckCache -->|Sim| CheckTTL{Ainda<br/>v√°lido?}
    
    CheckTTL -->|N√£o<br/>Expirado| RemoveExpired[Remove do cache]
    RemoveExpired --> Process
    
    CheckTTL -->|Sim| CacheHit[‚úÖ CACHE HIT<br/>Retorna imediato]
    CacheHit --> End([Response 200])
    
    Process --> Save[Salva no cache]
    Save --> End
    
    style CacheHit fill:#90EE90
    style Process fill:#FFB6C1
```

---

## Fun√ß√µes Principais

### 1Ô∏è‚É£ **`get_from_cache(idempotency_key: str) -> Optional[dict]`**

**Prop√≥sito:** Busca um resultado no cache se ainda v√°lido (dentro do TTL).

**L√≥gica:**
```python
def get_from_cache(idempotency_key: str) -> Optional[dict]:
    """
    1. Verifica se a chave existe no dicion√°rio _cache
    2. Se existir, pega o resultado e o timestamp
    3. Calcula a idade: datetime.now() - timestamp
    4. Se idade < TTL (24h): retorna resultado (CACHE HIT)
    5. Se idade >= TTL: remove do cache e retorna None (EXPIRED)
    6. Se n√£o existir: retorna None (CACHE MISS)
    """
```

**Retornos:**
- `dict` ‚Üí Resultado encontrado e v√°lido (CACHE HIT)
- `None` ‚Üí N√£o encontrado ou expirado (CACHE MISS ou EXPIRED)

**Logs emitidos:**
```python
# CACHE HIT
logger.info(
    f"[CACHE HIT] idempotency_key={idempotency_key[:16]}... | "
    f"age={idade_em_segundos:.1f}s | "
    f"cache_size={total_items_no_cache}"
)

# CACHE EXPIRED
logger.info(
    f"[CACHE EXPIRED] idempotency_key={idempotency_key[:16]}... | "
    f"age={idade_em_segundos:.1f}s"
)

# CACHE MISS (debug)
logger.debug(f"[CACHE MISS] idempotency_key={idempotency_key[:16]}...")
```

---

### 2Ô∏è‚É£ **`save_to_cache(idempotency_key: str, result: dict) -> None`**

**Prop√≥sito:** Salva um resultado no cache com timestamp atual.

**L√≥gica:**
```python
def save_to_cache(idempotency_key: str, result: dict) -> None:
    """
    1. Recebe o resultado processado (dict do Pydantic model)
    2. Cria tupla: (result, datetime.now())
    3. Salva no dicion√°rio: _cache[key] = (result, timestamp)
    4. Loga CACHE SAVE com tamanho atual do cache
    """
```

**Par√¢metros:**
- `idempotency_key`: SHA-256 hash (64 caracteres hex)
- `result`: Dict com `ExtractedMeeting.model_dump()` ou `AnalyzedMeeting.model_dump()`

**Logs emitidos:**
```python
logger.info(
    f"[CACHE SAVE] idempotency_key={idempotency_key[:16]}... | "
    f"cache_size={len(_cache)} | ttl={CACHE_TTL_HOURS}h"
)
```

---

### 3Ô∏è‚É£ **`clear_cache() -> int`**

**Prop√≥sito:** Limpa todo o cache e retorna quantos itens foram removidos.

**L√≥gica:**
```python
def clear_cache() -> int:
    """
    1. Conta quantos itens existem no cache
    2. Limpa o dicion√°rio: _cache.clear()
    3. Loga CACHE CLEARED
    4. Retorna quantidade removida
    """
```

**Uso:**
- √ötil para testes (limpar cache entre execu√ß√µes)
- Manuten√ß√£o manual
- Poss√≠vel endpoint `/admin/clear-cache` (n√£o implementado)

**Logs emitidos:**
```python
logger.info(f"[CACHE CLEARED] removed={count} items")
```

---

## Integra√ß√£o nos Endpoints

### üîç **Endpoint `/extract`**

#### Antes da Implementa√ß√£o (sem cache):
```python
@app.post("/extract")
async def extract_meeting(request, body):
    normalized = body.to_normalized()
    
    # SEMPRE processa com OpenAI (caro e lento)
    extracted = await extract_meeting_chain(normalized, request_id)
    
    return extracted
```

#### Depois da Implementa√ß√£o (com cache):
```python
@app.post("/extract")
async def extract_meeting(request, body):
    normalized = body.to_normalized()
    
    # 1. Calcula idempotency_key
    idempotency_key = normalized.compute_idempotency_key()
    
    # 2. Verifica cache (SE temos key v√°lida)
    if idempotency_key and idempotency_key != "no-idempotency-key-available":
        cached_result = get_from_cache(idempotency_key)
        
        if cached_result:
            # ‚úÖ CACHE HIT: retorna imediato (5ms)
            logger.info(f"üéØ Retornando do cache (idempotente)")
            return ExtractedMeeting(**cached_result)
    
    # 3. CACHE MISS: processa normalmente
    extracted = await extract_meeting_chain(normalized, request_id)
    
    # 4. Salva resultado no cache
    if idempotency_key and idempotency_key != "no-idempotency-key-available":
        save_to_cache(idempotency_key, extracted.model_dump())
    
    return extracted
```

### üîç **Endpoint `/analyze`**

**Implementa√ß√£o id√™ntica** ao `/extract`, mas usando:
- `analyze_sentiment_chain()` ao inv√©s de `extract_meeting_chain()`
- Retorna `AnalyzedMeeting` ao inv√©s de `ExtractedMeeting`

---

## Fluxo de Requisi√ß√µes

### üì• **Fluxo Completo com Cache**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. CLIENTE ENVIA REQUISI√á√ÉO POST /extract                           ‚îÇ
‚îÇ    {                                                                 ‚îÇ
‚îÇ      "transcript": "...",                                            ‚îÇ
‚îÇ      "metadata": {                                                   ‚îÇ
‚îÇ        "meeting_id": "MTG-001",                                      ‚îÇ
‚îÇ        "customer_id": "CUST-001",                                    ‚îÇ
‚îÇ        "meet_date": "2025-10-15T10:00:00Z"                           ‚îÇ
‚îÇ      }                                                               ‚îÇ
‚îÇ    }                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. MIDDLEWARE: add_request_id_and_metrics                           ‚îÇ
‚îÇ    - Gera UUID √∫nico: request_id = "876b6880-..."                   ‚îÇ
‚îÇ    - Anexa ao request.state.request_id                              ‚îÇ
‚îÇ    - Log: [INCOMING] [876b6880-...] POST /extract received          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. NORMALIZA√á√ÉO                                                      ‚îÇ
‚îÇ    - body.to_normalized() ‚Üí NormalizedInput                         ‚îÇ
‚îÇ    - Log: [876b6880-...] Normaliza√ß√£o conclu√≠da                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. CALCULAR IDEMPOTENCY_KEY                                          ‚îÇ
‚îÇ    idempotency_key = sha256(meeting_id + meet_date + customer_id)   ‚îÇ
‚îÇ    Result: "1294cd73c1b883ca35674a2104c3f15d..."                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. VERIFICAR CACHE                                                   ‚îÇ
‚îÇ    cached = get_from_cache("1294cd73c1b883ca...")                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ               ‚îÇ
         CACHE HIT ‚úÖ       CACHE MISS ‚ùå
                 ‚îÇ               ‚îÇ
                 ‚ñº               ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ 6A. RETORNAR CACHE ‚îÇ   ‚îÇ 6B. PROCESSAR COM OPENAI            ‚îÇ
    ‚îÇ (5ms)              ‚îÇ   ‚îÇ    - extract_meeting_chain()        ‚îÇ
    ‚îÇ                    ‚îÇ   ‚îÇ    - LLM prompting                  ‚îÇ
    ‚îÇ Log:               ‚îÇ   ‚îÇ    - JSON parsing                   ‚îÇ
    ‚îÇ üéØ [CACHE HIT]     ‚îÇ   ‚îÇ    - Valida√ß√£o Pydantic            ‚îÇ
    ‚îÇ age=10.5s          ‚îÇ   ‚îÇ    (5-10 segundos)                  ‚îÇ
    ‚îÇ cache_size=5       ‚îÇ   ‚îÇ                                     ‚îÇ
    ‚îÇ                    ‚îÇ   ‚îÇ Log:                                ‚îÇ
    ‚îÇ return ExtractedM  ‚îÇ   ‚îÇ üîç [CACHE MISS]                    ‚îÇ
    ‚îÇ         eeting(**  ‚îÇ   ‚îÇ processando normalmente             ‚îÇ
    ‚îÇ         cached)    ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
             ‚îÇ                              ‚ñº
             ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚îÇ              ‚îÇ 7. SALVAR NO CACHE                  ‚îÇ
             ‚îÇ              ‚îÇ    save_to_cache(key, result)       ‚îÇ
             ‚îÇ              ‚îÇ                                     ‚îÇ
             ‚îÇ              ‚îÇ Log:                                ‚îÇ
             ‚îÇ              ‚îÇ [CACHE SAVE]                        ‚îÇ
             ‚îÇ              ‚îÇ cache_size=6, ttl=24h               ‚îÇ
             ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                             ‚îÇ
             ‚ñº                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 8. RETORNAR RESPONSE 200                                             ‚îÇ
‚îÇ    {                                                                 ‚îÇ
‚îÇ      "meeting_id": "MTG-001",                                        ‚îÇ
‚îÇ      "summary": "...",                                               ‚îÇ
‚îÇ      "key_points": [...],                                            ‚îÇ
‚îÇ      "idempotency_key": "1294cd73c1b883ca...",                       ‚îÇ
‚îÇ      ...                                                             ‚îÇ
‚îÇ    }                                                                 ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ    Headers:                                                          ‚îÇ
‚îÇ      X-Request-ID: 876b6880-e91f-472f-a715-46ca4822cddb             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ‚è±Ô∏è **Compara√ß√£o de Performance**

| Cen√°rio | Etapas Executadas | Dura√ß√£o | Custo OpenAI |
|---------|------------------|---------|--------------|
| **CACHE MISS** (1¬™ requisi√ß√£o) | Normaliza√ß√£o ‚Üí C√°lculo Key ‚Üí Cache Miss ‚Üí OpenAI ‚Üí Save Cache ‚Üí Response | ~5-10s | ~$0.05-0.10 |
| **CACHE HIT** (2¬™+ requisi√ß√£o) | Normaliza√ß√£o ‚Üí C√°lculo Key ‚Üí Cache Hit ‚Üí Response | ~5-10ms | $0.00 |
| **Speedup** | - | **1000x** | **100%** |

---

## Logs e Monitoramento

### üîç **Tipos de Logs**

#### 1. **[CACHE HIT]** - Resultado encontrado no cache

```log
2025-10-14 22:42:28 - app.main - INFO - [CACHE HIT] idempotency_key=1294cd73c1b883ca... | age=3.1s | cache_size=1
2025-10-14 22:42:28 - app.main - INFO - üéØ [2908e027-...] Retornando do cache (idempotente) | idempotency_key=1294cd73c1b883ca... | ‚è±Ô∏è duration=0.005s
```

**Significado:**
- ‚úÖ Resultado foi encontrado no cache
- ‚úÖ Cache ainda est√° v√°lido (dentro do TTL de 24h)
- ‚úÖ Resposta retornada imediatamente (5ms)
- üìä `age=3.1s`: Entrada foi salva h√° 3.1 segundos
- üìä `cache_size=1`: Existe 1 item no cache total

**A√ß√£o:** Nenhuma. Sistema funcionando perfeitamente.

---

#### 2. **[CACHE MISS]** - Resultado n√£o encontrado no cache

```log
2025-10-14 22:42:20 - app.main - INFO - üîç [876b6880-...] Cache miss - processando normalmente | idempotency_key=1294cd73c1b883ca...
```

**Significado:**
- ‚ÑπÔ∏è Primeira vez que esta combina√ß√£o √© processada
- ‚ÑπÔ∏è Ou cache expirou (TTL > 24h)
- ‚ÑπÔ∏è Sistema ir√° processar com OpenAI

**A√ß√£o:** Normal. Aguardar processamento e salvamento no cache.

---

#### 3. **[CACHE SAVE]** - Resultado salvo no cache

```log
2025-10-14 22:42:25 - app.main - INFO - [CACHE SAVE] idempotency_key=1294cd73c1b883ca... | cache_size=1 | ttl=24h
```

**Significado:**
- ‚úÖ Resultado foi processado com sucesso pela OpenAI
- ‚úÖ Salvo no cache para requisi√ß√µes futuras
- üìä `cache_size=1`: Cache agora tem 1 item
- ‚è∞ `ttl=24h`: Este item expira em 24 horas

**A√ß√£o:** Pr√≥ximas requisi√ß√µes id√™nticas usar√£o este cache.

---

#### 4. **[CACHE EXPIRED]** - Cache expirou

```log
2025-10-15 22:45:00 - app.main - INFO - [CACHE EXPIRED] idempotency_key=1294cd73c1b883ca... | age=86401.0s
```

**Significado:**
- ‚è∞ Item existia no cache, mas expirou (> 24h)
- ‚ôªÔ∏è Item foi removido automaticamente
- ‚ÑπÔ∏è Sistema ir√° reprocessar

**A√ß√£o:** Normal. Cache com TTL funcionando corretamente.

---

#### 5. **[CACHE CLEARED]** - Cache limpo manualmente

```log
2025-10-15 10:00:00 - app.main - INFO - [CACHE CLEARED] removed=42 items
```

**Significado:**
- üóëÔ∏è Fun√ß√£o `clear_cache()` foi chamada
- üóëÔ∏è 42 itens foram removidos do cache

**A√ß√£o:** √ötil para testes ou manuten√ß√£o.

---

### üìä **Monitoramento de M√©tricas**

#### M√©tricas Relevantes (j√° implementadas no Prometheus):

```python
# Dura√ß√£o HTTP (cache hit vs miss vis√≠vel aqui)
http_request_duration_seconds{method="POST", path="/extract"}
  - Cache HIT: ~0.005s (5ms)
  - Cache MISS: ~5-10s

# Tokens OpenAI (cache hit n√£o gera tokens)
openai_tokens_total{type="total"}
  - Cache HIT: 0 tokens
  - Cache MISS: ~500-2000 tokens

# Custo estimado (cache hit = $0.00)
openai_estimated_cost_usd
  - Cache HIT: $0.00
  - Cache MISS: ~$0.05-0.10
```

#### Como Calcular Taxa de Cache Hit:

```
Cache Hit Rate = (Requisi√ß√µes com CACHE HIT) / (Total de Requisi√ß√µes)

Exemplo:
- 1000 requisi√ß√µes/dia
- 300 logs com [CACHE HIT]
- Hit Rate = 300/1000 = 30%
```

---

## Configura√ß√£o

### Vari√°vel de Ambiente

```bash
# .env ou vari√°vel de sistema

# TTL do cache em horas (padr√£o: 24)
CACHE_TTL_HOURS=24

# Exemplos:
CACHE_TTL_HOURS=1   # Cache expira em 1 hora (√∫til para dev/staging)
CACHE_TTL_HOURS=48  # Cache expira em 2 dias (produ√ß√£o com pouca mudan√ßa)
CACHE_TTL_HOURS=168 # Cache expira em 1 semana (m√°ximo recomendado)
```

### Como Funciona:

```python
# main.py - linha 103
CACHE_TTL_HOURS = int(os.getenv("CACHE_TTL_HOURS", "24"))

# Usado em get_from_cache():
if datetime.now() - timestamp < timedelta(hours=CACHE_TTL_HOURS):
    return result  # Ainda v√°lido
else:
    del _cache[idempotency_key]  # Expirou
    return None
```

### Recomenda√ß√µes por Ambiente:

| Ambiente | TTL Recomendado | Raz√£o |
|----------|----------------|-------|
| **Development** | 1-4 horas | Evita cache "preso" durante desenvolvimento |
| **Staging** | 12-24 horas | Testes realistas, mas permite refresh di√°rio |
| **Production** | 24-48 horas | M√°xima economia, dados raramente mudam |

---

## Testes

### üß™ **Script de Teste Automatizado**

Um script completo est√° dispon√≠vel em `tests/integration/test_cache_idempotency.py`:

```bash
# Com API rodando
python tests/integration/test_cache_idempotency.py
```

**O que o script faz:**

1. ‚úÖ Verifica health da API (`GET /health`)
2. üì§ Envia 1¬™ requisi√ß√£o (CACHE MISS esperado)
3. ‚è±Ô∏è Mede dura√ß√£o (~5-10s)
4. ‚è≥ Aguarda 1 segundo
5. üì§ Envia 2¬™ requisi√ß√£o ID√äNTICA (CACHE HIT esperado)
6. ‚è±Ô∏è Mede dura√ß√£o (~5ms)
7. üìä Compara resultados:
   - Idempotency keys devem ser id√™nticos
   - 2¬™ requisi√ß√£o deve ser **muito** mais r√°pida
   - Responses devem ser id√™nticos

**Sa√≠da esperada:**

```
================================================================================
üß™ TESTE DE CACHE DE IDEMPOT√äNCIA
================================================================================

1Ô∏è‚É£ Verificando health da API...
   ‚úÖ API est√° saud√°vel

2Ô∏è‚É£ Fazendo PRIMEIRA requisi√ß√£o (deve processar com OpenAI)...
   ‚úÖ Sucesso (status 200)
   ‚è±Ô∏è Dura√ß√£o: 7.51s
   üîë Idempotency Key: 1294cd73c1b883ca...

3Ô∏è‚É£ Aguardando 1 segundo antes da segunda requisi√ß√£o...

4Ô∏è‚É£ Fazendo SEGUNDA requisi√ß√£o (deve retornar do CACHE)...
   ‚úÖ Sucesso (status 200)
   ‚è±Ô∏è Dura√ß√£o: 0.005s
   üîë Idempotency Key: 1294cd73c1b883ca...

================================================================================
üìä AN√ÅLISE DOS RESULTADOS
================================================================================
‚è±Ô∏è Dura√ß√£o 1¬™ requisi√ß√£o: 7.510s
‚è±Ô∏è Dura√ß√£o 2¬™ requisi√ß√£o: 0.005s
üöÄ Speedup: 1502x mais r√°pido
‚úÖ CACHE FUNCIONANDO! Segunda requisi√ß√£o foi muito mais r√°pida.

‚úÖ Idempotency keys id√™nticos
‚úÖ Responses id√™nticos (idempot√™ncia garantida)
```

---

### üîß **Teste Manual via Swagger**

1. Abra `http://localhost:8000/docs`
2. Execute `POST /extract` com este payload:

```json
{
  "transcript": "Cliente: Ol√°, gostaria de investir.",
  "metadata": {
    "meeting_id": "TEST-001",
    "customer_id": "CUST-001",
    "meet_date": "2025-10-15T10:00:00Z"
  }
}
```

3. **Primeira execu√ß√£o:**
   - ‚è±Ô∏è Dura√ß√£o: ~5-10s
   - üìã Copie o `idempotency_key` do response

4. **Segunda execu√ß√£o (MESMO payload):**
   - ‚è±Ô∏è Dura√ß√£o: ~5-10ms
   - üìã `idempotency_key` deve ser id√™ntico
   - üìã Response completo deve ser id√™ntico

5. **Verificar logs:**

```bash
# PowerShell
Get-Content logs\info.log -Tail 50 | Select-String "CACHE"

# Voc√™ deve ver:
# [CACHE MISS] processando normalmente
# [CACHE SAVE] cache_size=1
# [CACHE HIT] age=5.2s | cache_size=1
```

---

## Pr√≥ximo N√≠vel: Redis

### üöÄ **Por Que Evoluir para Redis?**

O cache em mem√≥ria atual √© excelente para **single-instance deployments**, mas tem limita√ß√µes:

| Aspecto | Cache em Mem√≥ria | Cache Redis |
|---------|-----------------|-------------|
| **Persist√™ncia** | ‚ùå Perdido ao reiniciar | ‚úÖ Persiste em disco |
| **M√∫ltiplas inst√¢ncias** | ‚ùå Cache isolado por inst√¢ncia | ‚úÖ Cache compartilhado |
| **Escalabilidade horizontal** | ‚ùå N√£o funciona com load balancer | ‚úÖ Funciona perfeitamente |
| **Configura√ß√£o** | ‚úÖ Zero deps | ‚ö†Ô∏è Requer Redis server |
| **Performance** | ‚úÖ Lat√™ncia ~1¬µs (mem√≥ria) | ‚ö†Ô∏è Lat√™ncia ~1-5ms (rede) |
| **Complexidade** | ‚úÖ Simples | ‚ö†Ô∏è Moderada |

### üìã **Quando Migrar para Redis?**

‚úÖ **Migre SE:**
- Voc√™ tem m√∫ltiplas inst√¢ncias da API (load balancing)
- Precisa de cache que sobrevive a reinicializa√ß√µes
- Vai usar Kubernetes/Docker Swarm com autoscaling
- Quer monitoramento avan√ßado de cache

‚ùå **N√ÉO migre SE:**
- Uma √∫nica inst√¢ncia da API √© suficiente
- Quer simplicidade zero-dependency
- N√£o tem expertise para gerenciar Redis
- Performance atual j√° atende (~5ms cache hit)

---

## üõ†Ô∏è **Passo a Passo: Implementa√ß√£o com Redis**

### **FASE 1: Adicionar Redis ao Docker Compose** (15 min)

1. Edite `docker-compose.yml`:

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    depends_on:
      - redis
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL}
      - REDIS_URL=redis://redis:6379/0  # NOVO
      - CACHE_TTL_HOURS=24
    volumes:
      - ./logs:/app/logs

  redis:  # NOVO SERVICE
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru

volumes:
  redis_data:  # NOVO VOLUME
```

**Explica√ß√£o:**
- `redis:7-alpine`: Imagem oficial Redis (vers√£o 7, Alpine Linux)
- `--appendonly yes`: Persiste dados em disco (AOF)
- `--maxmemory 256mb`: Limite de RAM para cache
- `--maxmemory-policy allkeys-lru`: Remove itens antigos quando cheio (LRU = Least Recently Used)
- Volume `redis_data`: Garante persist√™ncia entre restarts

---

### **FASE 2: Adicionar Depend√™ncia Redis** (5 min)

2. Edite `requirements.txt`:

```txt
# ... depend√™ncias existentes ...
redis==5.0.1
```

3. Reinstale depend√™ncias:

```bash
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

---

### **FASE 3: Criar M√≥dulo Cache Manager** (30 min)

4. Crie `app/cache.py`:

```python
"""
Gerenciador de Cache com suporte a Redis.

Este m√≥dulo implementa um CacheManager que:
- Tenta conectar ao Redis se REDIS_URL estiver configurado
- Faz graceful degradation para mem√≥ria se Redis n√£o dispon√≠vel
- Exp√µe interface unificada independente do backend
"""

import json
import os
import logging
from typing import Optional, Dict, Tuple
from datetime import datetime, timedelta
import redis

logger = logging.getLogger(__name__)


class CacheManager:
    """
    Gerenciador de cache com fallback autom√°tico.
    
    Prioridade:
    1. Redis (se REDIS_URL configurado e dispon√≠vel)
    2. Mem√≥ria (fallback se Redis falhar)
    """
    
    def __init__(self):
        self.backend: str = "memory"
        self.client: Optional[redis.Redis] = None
        self._memory_cache: Dict[str, Tuple[dict, datetime]] = {}
        self.ttl_hours: int = int(os.getenv("CACHE_TTL_HOURS", "24"))
        
        # Tentar conectar ao Redis
        redis_url = os.getenv("REDIS_URL")
        if redis_url:
            try:
                self.client = redis.from_url(
                    redis_url,
                    decode_responses=True,  # Retorna strings ao inv√©s de bytes
                    socket_connect_timeout=5,
                    socket_timeout=5
                )
                # Testa conex√£o
                self.client.ping()
                self.backend = "redis"
                logger.info(f"‚úÖ Cache conectado ao Redis: {redis_url}")
            except Exception as e:
                logger.warning(
                    f"‚ö†Ô∏è Redis n√£o dispon√≠vel ({e}). "
                    f"Usando cache em mem√≥ria como fallback."
                )
                self.client = None
        else:
            logger.info("‚ÑπÔ∏è REDIS_URL n√£o configurado. Usando cache em mem√≥ria.")
    
    def get(self, key: str) -> Optional[dict]:
        """
        Busca um valor no cache.
        
        Args:
            key: Chave (idempotency_key)
            
        Returns:
            dict se encontrado e v√°lido, None caso contr√°rio
        """
        if self.backend == "redis" and self.client:
            return self._get_redis(key)
        else:
            return self._get_memory(key)
    
    def set(self, key: str, value: dict) -> None:
        """
        Salva um valor no cache.
        
        Args:
            key: Chave (idempotency_key)
            value: Dicion√°rio com o resultado (ExtractedMeeting ou AnalyzedMeeting)
        """
        if self.backend == "redis" and self.client:
            self._set_redis(key, value)
        else:
            self._set_memory(key, value)
    
    def clear(self) -> int:
        """
        Limpa todo o cache.
        
        Returns:
            N√∫mero de itens removidos
        """
        if self.backend == "redis" and self.client:
            return self._clear_redis()
        else:
            return self._clear_memory()
    
    # ========================================================================
    # Redis Backend
    # ========================================================================
    
    def _get_redis(self, key: str) -> Optional[dict]:
        """Busca no Redis."""
        try:
            data = self.client.get(f"idem:{key}")
            if data:
                logger.info(f"[CACHE HIT] [REDIS] {key[:16]}...")
                return json.loads(data)
            else:
                logger.debug(f"[CACHE MISS] [REDIS] {key[:16]}...")
                return None
        except Exception as e:
            logger.error(f"‚ùå [CACHE ERROR] Redis get: {e}")
            return None
    
    def _set_redis(self, key: str, value: dict) -> None:
        """Salva no Redis com TTL."""
        try:
            ttl_seconds = self.ttl_hours * 3600
            self.client.setex(
                f"idem:{key}",
                ttl_seconds,
                json.dumps(value)
            )
            # Pega tamanho do cache (aproximado)
            cache_size = self.client.dbsize()
            logger.info(
                f"[CACHE SAVE] [REDIS] {key[:16]}... | "
                f"cache_size‚âà{cache_size} | ttl={self.ttl_hours}h"
            )
        except Exception as e:
            logger.error(f"‚ùå [CACHE ERROR] Redis set: {e}")
    
    def _clear_redis(self) -> int:
        """Limpa todas as chaves com prefixo 'idem:'."""
        try:
            keys = self.client.keys("idem:*")
            count = len(keys)
            if count > 0:
                self.client.delete(*keys)
            logger.info(f"[CACHE CLEARED] [REDIS] removed={count} items")
            return count
        except Exception as e:
            logger.error(f"‚ùå [CACHE ERROR] Redis clear: {e}")
            return 0
    
    # ========================================================================
    # Memory Backend (Fallback)
    # ========================================================================
    
    def _get_memory(self, key: str) -> Optional[dict]:
        """Busca em mem√≥ria (mesma l√≥gica do original)."""
        if key in self._memory_cache:
            result, timestamp = self._memory_cache[key]
            
            # Verifica TTL
            if datetime.now() - timestamp < timedelta(hours=self.ttl_hours):
                age = (datetime.now() - timestamp).total_seconds()
                logger.info(
                    f"[CACHE HIT] [MEMORY] {key[:16]}... | "
                    f"age={age:.1f}s | cache_size={len(self._memory_cache)}"
                )
                return result
            else:
                # Expirado
                age = (datetime.now() - timestamp).total_seconds()
                del self._memory_cache[key]
                logger.info(
                    f"[CACHE EXPIRED] [MEMORY] {key[:16]}... | age={age:.1f}s"
                )
        
        logger.debug(f"[CACHE MISS] [MEMORY] {key[:16]}...")
        return None
    
    def _set_memory(self, key: str, value: dict) -> None:
        """Salva em mem√≥ria (mesma l√≥gica do original)."""
        self._memory_cache[key] = (value, datetime.now())
        logger.info(
            f"[CACHE SAVE] [MEMORY] {key[:16]}... | "
            f"cache_size={len(self._memory_cache)} | ttl={self.ttl_hours}h"
        )
    
    def _clear_memory(self) -> int:
        """Limpa cache em mem√≥ria."""
        count = len(self._memory_cache)
        self._memory_cache.clear()
        logger.info(f"[CACHE CLEARED] [MEMORY] removed={count} items")
        return count


# Singleton global (importado por main.py)
cache = CacheManager()
```

**Explica√ß√£o:**

1. **Tentativa de conex√£o Redis:**
   - Se `REDIS_URL` existe ‚Üí tenta conectar
   - Se conex√£o OK ‚Üí usa Redis
   - Se falha ‚Üí fallback para mem√≥ria (graceful degradation)

2. **Interface unificada:**
   - `cache.get(key)` ‚Üí busca no backend atual
   - `cache.set(key, value)` ‚Üí salva no backend atual
   - `cache.clear()` ‚Üí limpa cache do backend atual

3. **Logs informativos:**
   - `[REDIS]` ou `[MEMORY]` indica qual backend est√° ativo
   - Facilita debug e monitoramento

4. **Tratamento de erros:**
   - Se Redis cair durante execu√ß√£o ‚Üí loga erro mas n√£o quebra API
   - Fallback autom√°tico para mem√≥ria

---

### **FASE 4: Integrar CacheManager no main.py** (15 min)

5. Edite `app/main.py`:

**REMOVA as linhas antigas:**

```python
# REMOVER estas linhas (95-165):
# Cache em mem√≥ria: {idempotency_key: (result_dict, timestamp)}
_cache: Dict[str, Tuple[dict, datetime]] = {}
CACHE_TTL_HOURS = int(os.getenv("CACHE_TTL_HOURS", "24"))

def get_from_cache(idempotency_key: str) -> Optional[dict]:
    # ... c√≥digo antigo ...

def save_to_cache(idempotency_key: str, result: dict) -> None:
    # ... c√≥digo antigo ...

def clear_cache() -> int:
    # ... c√≥digo antigo ...
```

**ADICIONE no lugar:**

```python
# ============================================================================
# CACHE DE IDEMPOT√äNCIA (Redis com fallback para mem√≥ria)
# ============================================================================

from app.cache import cache

# Fun√ß√µes wrapper para compatibilidade (opcional, pode usar cache.get/set direto)
def get_from_cache(idempotency_key: str) -> Optional[dict]:
    """Wrapper para cache.get() (mant√©m compatibilidade com c√≥digo existente)."""
    return cache.get(idempotency_key)

def save_to_cache(idempotency_key: str, result: dict) -> None:
    """Wrapper para cache.set() (mant√©m compatibilidade com c√≥digo existente)."""
    cache.set(idempotency_key, result)

def clear_cache() -> int:
    """Wrapper para cache.clear() (mant√©m compatibilidade com c√≥digo existente)."""
    return cache.clear()
```

**Explica√ß√£o:**
- Importa o singleton `cache` de `app/cache.py`
- Mant√©m fun√ß√µes wrapper para n√£o quebrar c√≥digo existente
- Alternativamente, pode substituir `get_from_cache()` por `cache.get()` diretamente no c√≥digo

---

### **FASE 5: Testar Localmente** (20 min)

6. **Teste SEM Redis (fallback para mem√≥ria):**

```bash
# N√£o configure REDIS_URL
.\venv\Scripts\Activate.ps1
uvicorn app.main:app --reload

# Voc√™ deve ver no log de startup:
# ‚ÑπÔ∏è REDIS_URL n√£o configurado. Usando cache em mem√≥ria.
```

7. **Teste COM Redis (Docker Compose):**

```bash
# Inicie Redis
docker-compose up redis -d

# Configure env var
$env:REDIS_URL="redis://localhost:6379/0"

# Inicie API
uvicorn app.main:app --reload

# Voc√™ deve ver:
# ‚úÖ Cache conectado ao Redis: redis://localhost:6379/0
```

8. **Teste requisi√ß√µes duplicadas:**

```bash
# Execute script de teste
python tests/integration/test_cache_idempotency.py

# Voc√™ deve ver nos logs:
# [CACHE MISS] [REDIS] 1294cd73c1b883ca...
# [CACHE SAVE] [REDIS] 1294cd73c1b883ca... | cache_size‚âà1
# [CACHE HIT] [REDIS] 1294cd73c1b883ca...
```

9. **Valide persist√™ncia do Redis:**

```bash
# Fa√ßa uma requisi√ß√£o
curl -X POST http://localhost:8000/extract -H "Content-Type: application/json" -d '{...}'

# Reinicie a API (Ctrl+C e uvicorn novamente)
uvicorn app.main:app --reload

# Fa√ßa a MESMA requisi√ß√£o
curl -X POST http://localhost:8000/extract -H "Content-Type: application/json" -d '{...}'

# Deve ser CACHE HIT (cache sobreviveu ao restart!)
```

---

### **FASE 6: Deploy com Docker Compose** (10 min)

10. **Build e inicialize tudo:**

```bash
# Build da imagem
docker-compose build

# Inicialize API + Redis
docker-compose up

# Teste
curl http://localhost:8000/health
curl -X POST http://localhost:8000/extract -H "Content-Type: application/json" -d '{...}'
```

11. **Monitore Redis:**

```bash
# Conecte ao Redis CLI
docker-compose exec redis redis-cli

# Comandos √∫teis:
KEYS idem:*              # Lista todas as chaves de cache
GET idem:<key>           # V√™ conte√∫do de uma chave
TTL idem:<key>           # V√™ tempo restante at√© expira√ß√£o
DBSIZE                   # Quantidade de chaves
INFO memory              # Uso de mem√≥ria
FLUSHDB                  # Limpa cache (CUIDADO!)
```

---

### **FASE 7: Testes e Valida√ß√£o** (30 min)

12. **Crie teste de integra√ß√£o Redis:**

Arquivo: `tests/integration/test_cache_redis.py`

```python
"""
Testes de integra√ß√£o para cache Redis.

Requer Redis rodando em localhost:6379 ou REDIS_URL configurado.
"""

import pytest
import os
from app.cache import CacheManager


@pytest.fixture
def cache_manager():
    """Fixture que cria um CacheManager para testes."""
    # For√ßa uso de Redis para teste
    os.environ["REDIS_URL"] = "redis://localhost:6379/1"  # DB 1 (n√£o contamina prod)
    manager = CacheManager()
    yield manager
    # Cleanup ap√≥s teste
    manager.clear()


def test_redis_connection(cache_manager):
    """Testa se consegue conectar ao Redis."""
    assert cache_manager.backend == "redis"
    assert cache_manager.client is not None
    assert cache_manager.client.ping() is True


def test_redis_set_get(cache_manager):
    """Testa salvamento e recupera√ß√£o no Redis."""
    test_data = {"meeting_id": "TEST-001", "summary": "Test summary"}
    
    # Salva
    cache_manager.set("test-key-123", test_data)
    
    # Recupera
    result = cache_manager.get("test-key-123")
    
    assert result is not None
    assert result["meeting_id"] == "TEST-001"
    assert result["summary"] == "Test summary"


def test_redis_miss(cache_manager):
    """Testa CACHE MISS (chave n√£o existe)."""
    result = cache_manager.get("non-existent-key-xyz")
    assert result is None


def test_redis_clear(cache_manager):
    """Testa limpeza do cache."""
    # Salva 3 itens
    cache_manager.set("key1", {"data": "1"})
    cache_manager.set("key2", {"data": "2"})
    cache_manager.set("key3", {"data": "3"})
    
    # Limpa
    removed = cache_manager.clear()
    
    assert removed >= 3  # Pode ter outros itens de testes paralelos
    
    # Verifica que foram removidos
    assert cache_manager.get("key1") is None
    assert cache_manager.get("key2") is None
    assert cache_manager.get("key3") is None


def test_fallback_to_memory_if_redis_down():
    """Testa fallback para mem√≥ria se Redis n√£o dispon√≠vel."""
    # Configura URL inv√°lido
    os.environ["REDIS_URL"] = "redis://invalid-host:9999/0"
    
    manager = CacheManager()
    
    # Deve ter usado mem√≥ria como fallback
    assert manager.backend == "memory"
    assert manager.client is None
    
    # Mas ainda funciona
    manager.set("test-key", {"data": "test"})
    result = manager.get("test-key")
    assert result == {"data": "test"}
```

**Execute:**

```bash
# Com Redis rodando
pytest tests/integration/test_cache_redis.py -v

# Deve passar todos os 5 testes
```

---

### **FASE 8: Documenta√ß√£o e M√©tricas** (20 min)

13. **Adicione m√©tricas de cache ao Prometheus:**

Arquivo: `app/metrics/collectors.py` (adicione):

```python
# Cache metrics
cache_hits_total = Counter(
    'cache_hits_total',
    'Total number of cache hits',
    ['backend']  # redis ou memory
)

cache_misses_total = Counter(
    'cache_misses_total',
    'Total number of cache misses',
    ['backend']
)

cache_size_gauge = Gauge(
    'cache_size',
    'Current number of items in cache',
    ['backend']
)


def record_cache_hit(backend: str = "memory"):
    """Registra um cache hit."""
    cache_hits_total.labels(backend=backend).inc()


def record_cache_miss(backend: str = "memory"):
    """Registra um cache miss."""
    cache_misses_total.labels(backend=backend).inc()


def update_cache_size(size: int, backend: str = "memory"):
    """Atualiza tamanho do cache."""
    cache_size_gauge.labels(backend=backend).set(size)
```

14. **Integre m√©tricas no `cache.py`:**

```python
# No in√≠cio do arquivo
from app.metrics.collectors import record_cache_hit, record_cache_miss, update_cache_size

# Em _get_redis():
if data:
    record_cache_hit("redis")
    # ...
else:
    record_cache_miss("redis")
    # ...

# Em _set_redis():
record_cache_hit("redis")  # Salvamento conta como "uso" do cache
cache_size = self.client.dbsize()
update_cache_size(cache_size, "redis")

# Similar para _get_memory() e _set_memory()
```

15. **Verifique m√©tricas:**

```bash
curl http://localhost:8000/metrics | grep cache

# Voc√™ deve ver:
# cache_hits_total{backend="redis"} 42
# cache_misses_total{backend="redis"} 8
# cache_size{backend="redis"} 10
```

---

## üìä **Resumo da Migra√ß√£o**

### Antes (Cache em Mem√≥ria):
```
‚úÖ Simples (zero deps)
‚úÖ R√°pido (lat√™ncia ~1¬µs)
‚ùå N√£o persiste (perdido ao restart)
‚ùå N√£o funciona com m√∫ltiplas inst√¢ncias
```

### Depois (Cache Redis):
```
‚úÖ Persiste em disco
‚úÖ Compartilhado entre inst√¢ncias
‚úÖ Pronto para escalar horizontalmente
‚úÖ Graceful degradation (fallback mem√≥ria)
‚ö†Ô∏è Requer Redis server
‚ö†Ô∏è Lat√™ncia um pouco maior (~1-5ms)
```

### Esfor√ßo:
- **Tempo total**: 2-3 horas
- **Complexidade**: Moderada
- **Risco**: Baixo (fallback autom√°tico)

---

## ‚úÖ **Checklist Final**

Antes de considerar completo:

- [ ] Redis rodando no Docker Compose
- [ ] Vari√°vel `REDIS_URL` configurada
- [ ] `app/cache.py` criado e testado
- [ ] `main.py` atualizado para usar `CacheManager`
- [ ] Testes de integra√ß√£o passando
- [ ] M√©tricas Prometheus configuradas
- [ ] Logs mostrando `[REDIS]` ao inv√©s de `[MEMORY]`
- [ ] Cache persiste ap√≥s restart da API
- [ ] Documenta√ß√£o atualizada

---

**üéâ Parab√©ns! Voc√™ agora tem um sistema de cache production-ready com Redis!**


