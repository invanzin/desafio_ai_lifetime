# ğŸ§  DocumentaÃ§Ã£o: Analyzer (analyzer.py)

## ğŸ“š Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura LangChain](#arquitetura-langchain)
3. [Componentes Principais](#componentes-principais)
4. [Fluxo de AnÃ¡lise](#fluxo-de-anÃ¡lise)
5. [ValidaÃ§Ã£o de Sentimento](#validaÃ§Ã£o-de-sentimento)
6. [ResiliÃªncia e Retry](#resiliÃªncia-e-retry)
7. [Sistema de Reparo](#sistema-de-reparo)
8. [Logging e SeguranÃ§a](#logging-e-seguranÃ§a)
9. [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)

---

## ğŸ¯ VisÃ£o Geral

O arquivo `analyzer.py` Ã© o **cÃ©rebro da anÃ¡lise de sentimento** do microserviÃ§o. Ele Ã© responsÃ¡vel por:

âœ… Conectar com a OpenAI API (GPT-4o/GPT-4-turbo)  
âœ… Analisar sentimento (positive/neutral/negative)  
âœ… Calcular score numÃ©rico (0.0-1.0)  
âœ… Garantir consistÃªncia label â†” score  
âœ… Identificar riscos e insights estratÃ©gicos  
âœ… ResiliÃªncia com retry automÃ¡tico  
âœ… Reparar JSONs malformados  
âœ… Validar saÃ­da com Pydantic  
âœ… Logar tudo de forma segura (sem PII completa)

### Por que Temperature 0.2?

Ao contrÃ¡rio do **Extractor** (que usa `temperature=0` para ser determinÃ­stico), o **Analyzer** usa **`temperature=0.2`** porque:

- **AnÃ¡lise de sentimento Ã© subjetiva:** Permite certa variaÃ§Ã£o na interpretaÃ§Ã£o emocional
- **Insights criativos:** Temperatura baixa ainda mantÃ©m consistÃªncia, mas permite insights mais elaborados
- **BalanÃ§o ideal:** 0.2 Ã© baixo o suficiente para evitar "alucinaÃ§Ãµes", mas alto o suficiente para anÃ¡lises matizadas

**ComparaÃ§Ã£o:**
```python
# temperature=0 (EXTRACTOR - puramente determinÃ­stico)
"Cliente demonstrou interesse"
"Cliente demonstrou interesse"  # Sempre 100% igual

# temperature=0.2 (ANALYZER - levemente criativo)
"Cliente demonstrou otimismo moderado com reservas tÃ©cnicas"
"Cliente mostrou interesse positivo com preocupaÃ§Ãµes sobre prazo"
# Similar, mas permite variaÃ§Ãµes sutis na anÃ¡lise
```

---

## ğŸ—ï¸ Arquitetura LangChain

### Componentes da Chain

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LANGCHAIN CHAIN                       â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Prompt     â”‚ â†’ â”‚     LLM      â”‚ â†’ â”‚   Parser    â”‚ â”‚
â”‚  â”‚  Template    â”‚   â”‚  (ChatGPT)   â”‚   â”‚   (JSON)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  Input: transcript + metadata_json                       â”‚
â”‚  Output: dict Python com sentiment_label + score        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CÃ³digo Real

```python
# 1. Prompt Template (carregado do LangChain Hub)
prompt_hub_name = os.getenv("ANALYZER_PROMPT_HUB_NAME")
prompt = hub.pull(prompt_hub_name)
# Exemplo: "ivan-furukawa/analyzer-sentimento-bancario"

# 2. LLM (ChatGPT) com temperatura LIGEIRAMENTE CRIATIVA
llm = default_client.get_llm(temperature=0.2)  # â† DiferenÃ§a do Extractor!

# 3. Parser JSON
parser = JsonOutputParser()

# 4. Chain RAW (para capturar tokens)
chain_raw = prompt | llm

# 5. InvocaÃ§Ã£o (assÃ­ncrona)
raw_response = await chain_raw.ainvoke({
    "transcript": "Cliente: Estou muito satisfeito...",
    "metadata_json": '{"meeting_id": "MTG001"}'
})

# Parse manual do JSON
result = parser.parse(raw_response.content)

# Resultado: dict Python com anÃ¡lise completa!
{
    "sentiment_label": "positive",
    "sentiment_score": 0.85,
    "summary": "ReuniÃ£o positiva... (150 palavras)",
    "key_points": [...],
    "risks": [...]
}
```

---

## ğŸ§© Componentes Principais

### 1. InicializaÃ§Ã£o do LLM

```python
from llm.openai_client import default_client

llm = default_client.get_llm(temperature=0.2)
```

**ConfiguraÃ§Ã£o Completa (via `openai_client.py`):**
```python
ChatOpenAI(
    model="gpt-4o",           # Modelo padrÃ£o (env var)
    temperature=0.2,          # Levemente criativo
    timeout=30.0,             # Timeout de 30s
    api_key=os.getenv("OPENAI_API_KEY"),
    model_kwargs={
        "stream_usage": True  # Captura tokens para mÃ©tricas
    }
)
```

**Por que `temperature=0.2` Ã© ideal?**

| Temperature | Comportamento | Uso Ideal |
|-------------|---------------|-----------|
| 0.0 | 100% determinÃ­stico | ExtraÃ§Ã£o de dados estruturados |
| **0.2** | **Levemente criativo** | **AnÃ¡lise de sentimento** |
| 0.7 | Criativo e variado | Escrita criativa, brainstorm |
| 1.0 | Muito aleatÃ³rio | GeraÃ§Ã£o de ideias, poesia |

---

### 2. Prompt System (LangChain Hub)

Ao contrÃ¡rio do Extractor (que define o prompt em cÃ³digo), o Analyzer **carrega o prompt do LangChain Hub**:

```python
prompt_hub_name = os.getenv("ANALYZER_PROMPT_HUB_NAME")
# Exemplo: "ivan-furukawa/analyzer-sentimento-bancario"

try:
    logger.info(f"ğŸ”„ Carregando prompt do Hub: {prompt_hub_name}")
    prompt = hub.pull(prompt_hub_name)
    logger.debug(f"âœ… Prompt do Analyzer carregado com sucesso")
except Exception as e:
    logger.error(f"âŒ Falha ao carregar o prompt: {e}")
    raise
```

**BenefÃ­cios do LangChain Hub:**
- âœ… **Versionamento de prompts:** Atualizar sem mexer no cÃ³digo
- âœ… **A/B testing:** Testar diferentes prompts facilmente
- âœ… **ColaboraÃ§Ã£o:** Compartilhar prompts entre times
- âœ… **Rollback rÃ¡pido:** Reverter para versÃµes anteriores

**Estrutura TÃ­pica do Prompt:**
```
VocÃª Ã© um assistente especializado em anÃ¡lise de sentimento de reuniÃµes bancÃ¡rias.

**INSTRUÃ‡Ã•ES:**

1. **ANÃLISE DE SENTIMENTO:**
   - Classifique o sentimento geral em: "positive", "neutral", ou "negative"
   - Calcule um score numÃ©rico entre 0.0 e 1.0:
     * 0.0-0.4: negative (cliente insatisfeito, preocupado, frustrado)
     * 0.4-0.6: neutral (cliente neutro, sem emoÃ§Ãµes fortes)
     * 0.6-1.0: positive (cliente satisfeito, entusiasmado, confiante)

2. **CONSISTÃŠNCIA OBRIGATÃ“RIA:**
   - sentiment_label = "positive" â†’ sentiment_score >= 0.6
   - sentiment_label = "neutral" â†’ 0.4 <= sentiment_score < 0.6
   - sentiment_label = "negative" â†’ sentiment_score < 0.4

3. **IDENTIFICAÃ‡ÃƒO DE RISCOS:**
   - Identifique preocupaÃ§Ãµes, objeÃ§Ãµes ou sinais de alerta
   - Se nÃ£o houver riscos identificÃ¡veis, retorne lista vazia []

4. **FORMATO DE SAÃDA:**
Retorne um JSON vÃ¡lido:
{
  "sentiment_label": "positive|neutral|negative",
  "sentiment_score": 0.85,
  "summary": "Resumo de 100-200 palavras...",
  "key_points": ["Ponto 1", "Ponto 2"],
  "action_items": ["AÃ§Ã£o 1", "AÃ§Ã£o 2"],
  "risks": ["Risco 1"] ou []
}
```

---

### 3. FunÃ§Ãµes Auxiliares

O Analyzer **reutiliza funÃ§Ãµes compartilhadas** do mÃ³dulo `utils`:

```python
from utils import (
    sanitize_transcript_for_log,    # ProteÃ§Ã£o de PII
    prepare_metadata_for_prompt,    # FormataÃ§Ã£o de metadata
    repair_json,                    # Reparo de JSON
    extract_and_record_token_usage, # MÃ©tricas de tokens
    log_retry_attempt               # Log de retry
)
```

#### `sanitize_transcript_for_log()` - ProteÃ§Ã£o de PII

```python
transcript = "Cliente JoÃ£o Silva, CPF 123.456.789-00, estÃ¡ muito satisfeito..."

# Log SEGURO âœ…
logger.info(f"Transcript: {sanitize_transcript_for_log(transcript, 100)}")
# Output: "Cliente JoÃ£o Silva, CPF 123.456.789-00, estÃ¡ muito sa... (truncado, total: 523 chars)"
```

#### `prepare_metadata_for_prompt()` - FormataÃ§Ã£o de Metadata

```python
normalized = NormalizedInput(
    transcript="...",
    meeting_id="MTG001",
    customer_id="CUST001",
    meet_date=datetime(2025, 9, 10, 14, 30)
)

metadata_json = prepare_metadata_for_prompt(normalized)
# Resultado:
# {
#   "meeting_id": "MTG001",
#   "customer_id": "CUST001",
#   "meet_date": "2025-09-10T14:30:00"
# }
```

---

## ğŸ”„ Fluxo de AnÃ¡lise

### FunÃ§Ã£o Principal: `analyze_sentiment_chain()`

```python
@retry(
    reraise=True,
    stop=stop_after_attempt(3),  # MÃ¡ximo 3 tentativas
    wait=wait_exponential(multiplier=0.5, min=0.5, max=5.0),
    retry=retry_if_exception_type((RateLimitError, APITimeoutError, APIError)),
    before_sleep=log_retry_attempt,  # Log antes de cada retry
)
async def analyze_sentiment_chain(
    normalized: NormalizedInput,
    request_id: str = "-"
) -> AnalyzedMeeting:
    """
    Analisa sentimento e gera insights de uma reuniÃ£o usando OpenAI + LangChain.
    
    Orquestra todo o processo de anÃ¡lise:
    1. Valida dados de entrada
    2. Prepara os dados para o prompt
    3. Chama o LLM com retry automÃ¡tico (atÃ© 3 tentativas)
    4. Extrai tokens e registra mÃ©tricas Prometheus
    5. Valida o resultado com Pydantic (consistÃªncia label â†” score)
    6. Tenta reparar se a validaÃ§Ã£o falhar
    7. Preenche a chave de idempotÃªncia
    8. Retorna o objeto validado
    """
```

### Passo a Passo Detalhado

#### Passo 1: PreparaÃ§Ã£o

```python
# Log inÃ­cio (sem PII completa)
logger.info(
    f"[ANALYZE] [{request_id}] ğŸ§  Iniciando anÃ¡lise de sentimento | "
    f"transcript_len={len(normalized.transcript)} | "
    f"has_metadata={'sim' if normalized.meeting_id else 'nÃ£o'}"
)

# Prepara metadados para o prompt
metadata_json = prepare_metadata_for_prompt(normalized)
metadata_fields_count = len(json.loads(metadata_json)) if metadata_json != '{}' else 0

logger.info(
    f"[{request_id}] ğŸ¤– Chamada Ã  OpenAI | "
    f"metadata_fields={metadata_fields_count} | "
    f"transcript_preview={sanitize_transcript_for_log(normalized.transcript, 100)}"
)
```

#### Passo 2: Chamada ao LLM (com captura de tokens)

```python
# Prepara configuraÃ§Ã£o para LangSmith (observabilidade)
trace_config = {
    "metadata": {
        "request_id": request_id,
        "transcript_length": len(normalized.transcript),
        "has_metadata_input": bool(metadata_fields_count > 0)
    },
    "run_name": f"Analyze Meeting - {request_id}"
}

# ğŸ”¥ Chain RAW para capturar metadados de tokens
llm_start = time.time()
raw_response = await chain_raw.ainvoke(
    {
        "transcript": normalized.transcript,
        "metadata_json": metadata_json
    },
    config=trace_config
)

# Registra mÃ©tricas Prometheus
model = get_model_from_env()  # Ex: "gpt-4o"
record_openai_request(model, "success")

# Extrai e registra tokens (prompt_tokens, completion_tokens)
extract_and_record_token_usage(raw_response, model, request_id)

# Parse manual do JSON
raw_output = parser.parse(raw_response.content)

llm_duration = time.time() - llm_start
logger.info(
    f"[RESPONSE] [{request_id}] âœ… OpenAI API respondeu | "
    f"duration={llm_duration:.2f}s | "
    f"output_keys={list(raw_output.keys())}"
)
```

**Por que Chain RAW ao invÃ©s de Chain com Parser?**

```python
# âŒ Chain com parser direto (nÃ£o captura tokens)
chain = prompt | llm | parser
result = await chain.ainvoke(...)
# Problema: `result` jÃ¡ Ã© dict, perdemos acesso aos metadados do LLM!

# âœ… Chain RAW + parse manual (captura tokens)
chain_raw = prompt | llm
raw_response = await chain_raw.ainvoke(...)
# raw_response.usage.prompt_tokens â† DisponÃ­vel!
# raw_response.usage.completion_tokens â† DisponÃ­vel!
result = parser.parse(raw_response.content)
```

#### Passo 3: ValidaÃ§Ã£o com Pydantic

```python
try:
    analyzed = AnalyzedMeeting.model_validate(raw_output)
    logger.debug(f"[SUCCESS] [{request_id}] âœ… ValidaÃ§Ã£o Pydantic OK")
    
    logger.info(
        f"[SUCCESS] [{request_id}] ğŸ‰ AnÃ¡lise concluÃ­da | "
        f"sentiment={analyzed.sentiment_label} | "
        f"score={analyzed.sentiment_score:.2f} | "
        f"summary_words={len(analyzed.summary.split())} | "
        f"risks={len(analyzed.risks)}"
    )

except Exception as validation_error:
    # ValidaÃ§Ã£o falhou â†’ tenta reparar UMA vez
    logger.warning(
        f"[VALIDATION] [{request_id}] âš ï¸ ValidaÃ§Ã£o falhou | "
        f"erro={type(validation_error).__name__}: {str(validation_error)[:200]}"
    )
    
    repaired_output = await repair_json(
        malformed_output=raw_output,
        validation_error=str(validation_error),
        normalized=normalized,
        request_id=request_id,
        schema_type="analyze"  # â† Indica schema do Analyzer
    )
    
    # Tenta validar novamente
    analyzed = AnalyzedMeeting.model_validate(repaired_output)
    logger.info(f"[SUCCESS] [{request_id}] âœ… ValidaÃ§Ã£o OK apÃ³s reparo")
    
    # Registra mÃ©trica de reparo
    record_repair_attempt("success")
```

#### Passo 4: Preenchimento da Idempotency Key

```python
# Preenche a chave de idempotÃªncia se possÃ­vel
idem_key = normalized.compute_idempotency_key()
if idem_key:
    analyzed.idempotency_key = idem_key
    logger.debug(f"[IDEM] [{request_id}] ğŸ”‘ Idempotency key: {idem_key[:16]}...")
else:
    # Se nÃ£o for possÃ­vel calcular, usa placeholder
    analyzed.idempotency_key = "no-idempotency-key-available"
    logger.warning(
        f"[IDEM] [{request_id}] âš ï¸ NÃ£o foi possÃ­vel calcular idempotency_key"
    )

return analyzed
```

---

## ğŸ­ ValidaÃ§Ã£o de Sentimento

### ConsistÃªncia Label â†” Score

O `AnalyzedMeeting` possui um validador customizado que **garante consistÃªncia** entre `sentiment_label` e `sentiment_score`:

```python
@model_validator(mode='after')
def validate_sentiment_consistency(self):
    """
    Regras de consistÃªncia:
    - "positive": score >= 0.6
    - "neutral": 0.4 <= score < 0.6
    - "negative": score < 0.4
    """
    label = self.sentiment_label
    score = self.sentiment_score
    
    if label == "positive" and score < 0.6:
        raise ValueError(
            f"sentiment_label 'positive' requer score >= 0.6, recebido: {score}"
        )
    elif label == "neutral" and not (0.4 <= score < 0.6):
        raise ValueError(
            f"sentiment_label 'neutral' requer 0.4 <= score < 0.6, recebido: {score}"
        )
    elif label == "negative" and score >= 0.4:
        raise ValueError(
            f"sentiment_label 'negative' requer score < 0.4, recebido: {score}"
        )
    
    return self
```

**Exemplos:**

```python
# âœ… VÃLIDO - Consistente
AnalyzedMeeting(
    sentiment_label="positive",
    sentiment_score=0.85,  # >= 0.6 âœ“
    # ... outros campos
)

# âŒ INVÃLIDO - Inconsistente
AnalyzedMeeting(
    sentiment_label="positive",
    sentiment_score=0.3,  # < 0.6 âœ—
    # ... outros campos
)
# ValidationError: sentiment_label 'positive' requer score >= 0.6, recebido: 0.3

# âœ… VÃLIDO - Neutral
AnalyzedMeeting(
    sentiment_label="neutral",
    sentiment_score=0.5,  # 0.4 <= 0.5 < 0.6 âœ“
    # ... outros campos
)

# âŒ INVÃLIDO - Neutral com score alto
AnalyzedMeeting(
    sentiment_label="neutral",
    sentiment_score=0.7,  # >= 0.6 âœ—
    # ... outros campos
)
# ValidationError: sentiment_label 'neutral' requer 0.4 <= score < 0.6, recebido: 0.7
```

### Tabela de ConsistÃªncia

| sentiment_label | sentiment_score | VÃ¡lido? | Exemplo de ReuniÃ£o |
|-----------------|-----------------|---------|-------------------|
| **positive** | 0.85 | âœ… | Cliente muito satisfeito, fechou negÃ³cio |
| **positive** | 0.6 | âœ… | Cliente satisfeito, sem objeÃ§Ãµes graves |
| **positive** | 0.55 | âŒ | Score muito baixo para "positive" |
| **neutral** | 0.5 | âœ… | Cliente sem emoÃ§Ãµes fortes |
| **neutral** | 0.45 | âœ… | Cliente levemente positivo |
| **neutral** | 0.7 | âŒ | Score muito alto para "neutral" |
| **negative** | 0.3 | âœ… | Cliente insatisfeito, com objeÃ§Ãµes |
| **negative** | 0.1 | âœ… | Cliente muito frustrado |
| **negative** | 0.5 | âŒ | Score muito alto para "negative" |

---

## ğŸ” ResiliÃªncia e Retry

### Decorator `@retry`

IdÃªntico ao Extractor, o Analyzer usa o mesmo sistema de retry:

```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

@retry(
    reraise=True,
    stop=stop_after_attempt(3),             # MÃ¡ximo 3 tentativas
    wait=wait_exponential(                  # Backoff exponencial
        multiplier=0.5, 
        min=0.5, 
        max=5.0
    ),
    retry=retry_if_exception_type((         # Apenas para esses erros
        RateLimitError,                      # 429 - Too Many Requests
        APITimeoutError,                     # Timeout de rede
        APIError                             # Erro genÃ©rico da API
    )),
    before_sleep=log_retry_attempt          # â† Log antes de cada retry
)
async def analyze_sentiment_chain(...):
    ...
```

### Log de Retry (via `log_retry_attempt`)

```python
# utils/retry_logger.py
def log_retry_attempt(retry_state):
    """Log antes de cada retry."""
    attempt = retry_state.attempt_number
    wait_time = retry_state.next_action.sleep
    exception = retry_state.outcome.exception()
    
    logger.warning(
        f"[RETRY] Tentativa {attempt}/3 falhou | "
        f"erro={type(exception).__name__} | "
        f"aguardando {wait_time:.1f}s antes de retry..."
    )
```

**Exemplo de SequÃªncia de Logs:**

```
[ANALYZE] [req-123] ğŸ§  Iniciando anÃ¡lise de sentimento | transcript_len=790
[req-123] ğŸ¤– Chamada Ã  OpenAI | metadata_fields=2
[ERROR] [req-123] âŒ OpenAI API Error: RateLimitError - Too Many Requests
[RETRY] Tentativa 1/3 falhou | erro=RateLimitError | aguardando 0.5s...
[req-123] ğŸ¤– Chamada Ã  OpenAI | metadata_fields=2 (RETRY 2/3)
[RESPONSE] [req-123] âœ… OpenAI API respondeu | duration=4.2s
[SUCCESS] [req-123] âœ… ValidaÃ§Ã£o Pydantic OK
[SUCCESS] [req-123] ğŸ‰ AnÃ¡lise concluÃ­da | sentiment=positive | score=0.85
```

---

## ğŸ”§ Sistema de Reparo

### Quando o Reparo Ã© Ativado?

Quando a **validaÃ§Ã£o Pydantic falha** no output do LLM:

**CenÃ¡rio 1: InconsistÃªncia label â†” score**
```python
# LLM retornou
{
    "sentiment_label": "positive",
    "sentiment_score": 0.3,  # âŒ Inconsistente!
    ...
}

# Pydantic tenta validar
analyzed = AnalyzedMeeting.model_validate(raw_output)
# ValidationError: sentiment_label 'positive' requer score >= 0.6, recebido: 0.3

# Sistema detecta erro e chama reparo
```

**CenÃ¡rio 2: Summary muito curto**
```python
{
    "summary": "Breve resumo",  # âŒ Apenas 2 palavras (precisa 100-200)
    ...
}

# ValidationError: summary deve ter 100-200 palavras, tem 2
```

### FunÃ§Ã£o `repair_json()` (Compartilhada)

```python
# utils/json_repair.py
async def repair_json(
    malformed_output: dict,
    validation_error: str,
    normalized: NormalizedInput,
    request_id: str,
    schema_type: str  # â† "analyze" ou "extract"
) -> dict:
    """
    Tenta reparar um JSON malformado reenviando ao LLM com o erro.
    
    Args:
        schema_type: "analyze" ou "extract" (determina schema esperado)
    """
    
    logger.warning(
        f"[REPAIR] [{request_id}] ğŸ”§ Tentando reparar JSON | "
        f"schema={schema_type} | erro={validation_error[:200]}"
    )
    
    # Carrega prompt de reparo do Hub
    repair_prompt_hub = os.getenv("JSON_REPAIRER_PROMPT_HUB_NAME")
    repair_prompt = hub.pull(repair_prompt_hub)
    
    # Seleciona schema correto
    if schema_type == "analyze":
        schema_doc = """
        - sentiment_label: "positive"|"neutral"|"negative"
        - sentiment_score: float (0.0-1.0)
        - ConsistÃªncia: positive (â‰¥0.6), neutral (0.4-0.6), negative (<0.4)
        - summary: string (100-200 palavras EXATAS)
        - key_points: array de strings
        - action_items: array de strings
        - risks: array de strings (pode ser vazio [])
        """
    else:
        schema_doc = """
        - summary: string (100-200 palavras EXATAS)
        - key_points: array de strings
        - action_items: array de strings
        - topics: array de strings
        """
    
    # Chain de reparo
    repair_chain = repair_prompt | llm | parser
    
    repaired = await repair_chain.ainvoke({
        "malformed_json": json.dumps(malformed_output, ensure_ascii=False, indent=2),
        "error": validation_error,
        "transcript_preview": sanitize_transcript_for_log(normalized.transcript, 500),
        "schema": schema_doc
    })
    
    logger.info(f"[REPAIR] [{request_id}] âœ… JSON reparado com sucesso")
    return repaired
```

### Exemplo de Reparo - Analyzer

**Input para reparo:**
```json
{
  "malformed_json": {
    "sentiment_label": "positive",
    "sentiment_score": 0.3,
    "summary": "Cliente satisfeito... (150 palavras)",
    ...
  },
  "error": "sentiment_label 'positive' requer score >= 0.6, recebido: 0.3",
  "schema": "analyze"
}
```

**LLM processa e retorna JSON corrigido:**
```json
{
  "sentiment_label": "neutral",
  "sentiment_score": 0.45,
  "summary": "Cliente satisfeito... (150 palavras)",
  ...
}
```
**ValidaÃ§Ã£o (2Âª tentativa):**
```python
analyzed = AnalyzedMeeting.model_validate(repaired_output)
# âœ… OK! (neutral com score 0.45 Ã© consistente)
```

---

## ğŸ“Š Logging e SeguranÃ§a

### Estrutura de Logs

Todos os logs seguem o padrÃ£o com tags especÃ­ficas:

```
[TAG] [REQUEST_ID] emoji Mensagem | contexto_key=valor
```

**Tags usadas no Analyzer:**
- `[ANALYZE]` - InÃ­cio da anÃ¡lise
- `[RESPONSE]` - Resposta da OpenAI
- `[SUCCESS]` - AnÃ¡lise concluÃ­da
- `[ERROR]` - Erro na API
- `[VALIDATION]` - Erro de validaÃ§Ã£o
- `[REPAIR]` - Reparo de JSON
- `[IDEM]` - Idempotency key

### Exemplo de SequÃªncia de Logs Completa

```
[ANALYZE] [req-abc] ğŸ§  Iniciando anÃ¡lise de sentimento | transcript_len=790 | has_metadata=sim
[req-abc] ğŸ¤– Chamada Ã  OpenAI | metadata_fields=3 | transcript_preview=Cliente: Estou muito...
[RESPONSE] [req-abc] âœ… OpenAI API respondeu com sucesso | duration=3.8s | output_keys=['sentiment_label', 'sentiment_score', ...]
[SUCCESS] [req-abc] âœ… ValidaÃ§Ã£o Pydantic OK na primeira tentativa
[SUCCESS] [req-abc] ğŸ‰ AnÃ¡lise concluÃ­da com sucesso | sentiment=positive | score=0.85 | summary_words=169 | risks=0
[IDEM] [req-abc] ğŸ”‘ Idempotency key calculada: 7e3e97ffd83f...
```

### O que Ã‰ e NÃƒO Ã‰ Logado

âœ… **Ã‰ logado:**
- Request ID (rastreamento)
- Tamanho da transcriÃ§Ã£o (nÃºmero de caracteres)
- PresenÃ§a de metadados (sim/nÃ£o)
- NÃºmero de campos de metadata
- Preview de 100 chars da transcriÃ§Ã£o
- Chaves do JSON retornado pelo LLM
- Status de validaÃ§Ã£o (OK/FALHA)
- Sentiment label e score
- NÃºmero de palavras do summary
- Quantidade de key_points/action_items/risks
- Tipos de erros (sem detalhes sensÃ­veis)
- DuraÃ§Ã£o das chamadas

âŒ **NÃƒO Ã© logado:**
- TranscriÃ§Ã£o completa
- Nomes de clientes/bankers
- ConteÃºdo do resumo
- IDs completos de clientes
- CPFs, emails, telefones
- Detalhes financeiros
- Insights especÃ­ficos

---

## ğŸ“ Exemplos PrÃ¡ticos

### Exemplo 1: AnÃ¡lise Positiva (1Âª Tentativa)

```python
# Input
normalized = NormalizedInput(
    transcript="Cliente: Estou muito satisfeito com a proposta! Vamos fechar hoje mesmo.",
    meeting_id="MTG001",
    customer_id="CUST001",
    meet_date=datetime(2025, 9, 10, 14, 30)
)

# Chamada
analyzed = await analyze_sentiment_chain(normalized, "req-123")

# Logs:
# [ANALYZE] [req-123] ğŸ§  Iniciando anÃ¡lise | transcript_len=68
# [req-123] ğŸ¤– Chamada Ã  OpenAI | metadata_fields=3
# [RESPONSE] [req-123] âœ… OpenAI respondeu | duration=3.2s
# [SUCCESS] [req-123] âœ… ValidaÃ§Ã£o OK
# [SUCCESS] [req-123] ğŸ‰ AnÃ¡lise concluÃ­da | sentiment=positive | score=0.92

# Output
print(analyzed.sentiment_label)  # "positive"
print(analyzed.sentiment_score)  # 0.92
print(len(analyzed.summary.split()))  # 145 palavras
print(analyzed.risks)  # []
```

### Exemplo 2: AnÃ¡lise Negativa com Riscos

```python
# Input
normalized = NormalizedInput(
    transcript="Cliente: Estou preocupado com as taxas. NÃ£o sei se consigo pagar...",
    meeting_id="MTG002",
    customer_id="CUST002",
    meet_date=datetime(2025, 9, 11, 10, 0)
)

# Chamada
analyzed = await analyze_sentiment_chain(normalized, "req-456")

# Output
print(analyzed.sentiment_label)  # "negative"
print(analyzed.sentiment_score)  # 0.25
print(analyzed.risks)
# [
#   "Cliente demonstrou preocupaÃ§Ã£o com capacidade de pagamento",
#   "ObjeÃ§Ã£o forte sobre taxas cobradas"
# ]
```

### Exemplo 3: Reparo por InconsistÃªncia

```python
# LLM retornou (inconsistente)
{
    "sentiment_label": "positive",
    "sentiment_score": 0.4,  # âŒ Deveria ser >= 0.6
    ...
}

# Logs:
# [VALIDATION] [req-789] âš ï¸ ValidaÃ§Ã£o falhou | erro=ValueError: sentiment_label 'positive' requer score >= 0.6, recebido: 0.4
# [REPAIR] [req-789] ğŸ”§ Tentando reparar JSON | schema=analyze
# [REPAIR] [req-789] âœ… JSON reparado com sucesso
# [SUCCESS] [req-789] âœ… ValidaÃ§Ã£o OK apÃ³s reparo

# JSON reparado
{
    "sentiment_label": "neutral",
    "sentiment_score": 0.45,  # âœ… Consistente
    ...
}
```

### Exemplo 4: Retry por Rate Limit

```python
# Tentativa 1
[ANALYZE] [req-999] ğŸ§  Iniciando anÃ¡lise
[ERROR] [req-999] âŒ OpenAI API Error: RateLimitError
[RETRY] Tentativa 1/3 falhou | erro=RateLimitError | aguardando 0.5s...

# Tentativa 2
[req-999] ğŸ¤– Chamada Ã  OpenAI (RETRY 2/3)
[RESPONSE] [req-999] âœ… OpenAI respondeu | duration=4.1s
[SUCCESS] [req-999] âœ… ValidaÃ§Ã£o OK
```

---

## ğŸ’¡ Dicas e Boas PrÃ¡ticas

### 1. Temperature Adequada por Uso

```python
# âœ… BOM - Extrator (determinÃ­stico)
llm_extract = ChatOpenAI(temperature=0)

# âœ… BOM - Analyzer (levemente criativo)
llm_analyze = ChatOpenAI(temperature=0.2)

# âŒ RUIM - Analyzer muito criativo (inconsistente)
llm_analyze = ChatOpenAI(temperature=0.7)
```

### 2. ValidaÃ§Ã£o de ConsistÃªncia

```python
# âœ… BOM - Validador customizado
@model_validator(mode='after')
def validate_sentiment_consistency(self):
    # Garante label â†” score consistentes
    ...

# âŒ RUIM - Sem validaÃ§Ã£o (aceita inconsistÃªncias)
sentiment_label: Literal["positive", "neutral", "negative"]
sentiment_score: float  # Sem check de consistÃªncia
```

### 3. Logs Estruturados com Emojis

```python
# âœ… BOM - FÃ¡cil de identificar visualmente
logger.info(f"[ANALYZE] [{request_id}] ğŸ§  Iniciando anÃ¡lise")
logger.info(f"[SUCCESS] [{request_id}] ğŸ‰ AnÃ¡lise concluÃ­da")
logger.error(f"[ERROR] [{request_id}] âŒ Falha na API")

# âŒ RUIM - DifÃ­cil de parsear
logger.info(f"Analisando sentimento para {request_id}")
```

### 4. Campo `risks` Opcional mas Sempre Lista

```python
# âœ… BOM - Sempre retorna lista (pode ser vazia)
risks: List[str] = Field(default_factory=list)

# âŒ RUIM - None pode causar erros
risks: Optional[List[str]] = None
```

---

## ğŸ“Š MÃ©tricas de Performance

| MÃ©trica | Valor TÃ­pico | ObservaÃ§Ã£o |
|---------|--------------|------------|
| **Tempo mÃ©dio de anÃ¡lise** | 3-6 segundos | Temperature 0.2 Ã© ligeiramente mais lento |
| **Taxa de sucesso (1Âª tentativa)** | ~92% | Menor que Extractor devido a validaÃ§Ãµes complexas |
| **Taxa de reparo bem-sucedido** | ~80% | InconsistÃªncia label â†” score Ã© comum |
| **Taxa de retry por rate limit** | ~2% | IdÃªntico ao Extractor |
| **Taxa de falha definitiva** | <1% | Muito raro |
| **% Positive** | ~45% | Depende do dataset |
| **% Neutral** | ~35% | Depende do dataset |
| **% Negative** | ~20% | Depende do dataset |

---

## ğŸ” Debugging

### Como debugar erros de anÃ¡lise?

1. **Verifique os logs com o Request ID:**
```bash
grep "req-123" logs.txt | grep ANALYZE
```

2. **Teste o prompt manualmente:**
```python
# No console Python
from app.analyzers.analyzer import prompt, llm, parser

result = await (prompt | llm).ainvoke({
    "transcript": "Cliente: Teste...",
    "metadata_json": "{}"
})
print(result.content)
```

3. **Valide o output manualmente:**
```python
from app.models.schemas_analyze import AnalyzedMeeting

try:
    analyzed = AnalyzedMeeting.model_validate(result)
except Exception as e:
    print(f"Erro: {e}")
```

4. **Teste consistÃªncia label â†” score:**
```python
# Deve falhar
AnalyzedMeeting(
    sentiment_label="positive",
    sentiment_score=0.3,  # âŒ
    ...
)
# ValidationError: sentiment_label 'positive' requer score >= 0.6, recebido: 0.3
```

---

## ğŸ“š DiferenÃ§as Extractor vs Analyzer

| Aspecto | Extractor | Analyzer |
|---------|-----------|----------|
| **Temperature** | 0 (determinÃ­stico) | 0.2 (levemente criativo) |
| **Output Principal** | Dados estruturados | Sentimento + insights |
| **ValidaÃ§Ãµes** | Summary 100-200 palavras | + ConsistÃªncia label â†” score |
| **Campo Diferencial** | `topics` | `sentiment_label`, `sentiment_score`, `risks` |
| **Prompt** | Definido em cÃ³digo | Carregado do LangChain Hub |
| **Uso** | ExtraÃ§Ã£o de fatos | AnÃ¡lise subjetiva |
| **Taxa de Reparo** | ~85% | ~80% (validaÃ§Ãµes mais complexas) |

---

## ğŸ“š ReferÃªncias

- **LangChain Docs:** https://python.langchain.com/docs/get_started/introduction
- **LangChain Hub:** https://smith.langchain.com/hub
- **OpenAI API:** https://platform.openai.com/docs/api-reference
- **Tenacity (Retry):** https://tenacity.readthedocs.io/

---

**PrÃ³ximo:** [05-TESTS.md](05-TESTS.md) - Como testar o Analyzer


