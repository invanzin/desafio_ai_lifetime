"""
API Principal do Microservi√ßo de Extra√ß√£o de Reuni√µes.

Este m√≥dulo implementa o endpoint FastAPI para extra√ß√£o estruturada de informa√ß√µes
de transcri√ß√µes de reuni√µes banc√°rias usando OpenAI API + LangChain.

Endpoints:
    POST /extract: Extrai informa√ß√µes estruturadas de uma transcri√ß√£o
    GET /health: Health check da aplica√ß√£o

Caracter√≠sticas:
    - Valida√ß√£o autom√°tica com Pydantic
    - Idempot√™ncia via SHA-256
    - Logs estruturados (sem PII completa)
    - Retry autom√°tico e timeouts
    - Tratamento robusto de erros
    - Documenta√ß√£o autom√°tica (OpenAPI/Swagger)
"""

import uuid
import logging
import os
from contextlib import asynccontextmanager
from typing import Dict, Any

from fastapi import FastAPI, Request, status
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from pydantic import ValidationError

from fastapi.responses import Response

# Rate Limiting
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

# M√©tricas Prometheus
from prometheus_fastapi_instrumentator import Instrumentator

# OpenAI exceptions para error handling
from openai import RateLimitError, APITimeoutError, APIError

# Schemas de valida√ß√£o
from app.models.schemas_common import NormalizedInput
from app.models.schemas_extract import ExtractRequest, ExtractedMeeting

# Extractor principal
from app.extractors.extractor import extract_meeting_chain

# Configura√ß√£o de logging centralizada
from app.config.logging_config import setup_logging, get_logger

# Importa coletores de m√©tricas para registr√°-los
from app.metrics import collectors
from app.metrics.collectors import (
    record_rate_limit_exceeded,
    record_http_request,
    record_http_duration,
    record_transcript_size,
    record_meeting_extracted,
    record_api_error,
    extraction_duration_seconds,
)


# ============================================================================
# CONFIGURA√á√ÉO DE LOGGING
# ============================================================================

# Inicializa logging imediatamente (importante para testes)
# O setup_logging ser√° chamado novamente no lifespan se necess√°rio
setup_logging(log_level="DEBUG", console_output=True)
logger = get_logger(__name__)


# ============================================================================
# CONFIGURA√á√ÉO DE RATE LIMITING
# ============================================================================

# Cria inst√¢ncia do Limiter para prote√ß√£o contra abuse
# - key_func: Usa IP do cliente para rastrear requisi√ß√µes
# - default_limits: Sem limite global (definimos por endpoint)
# - storage_uri: Usa mem√≥ria (ideal para single-instance deployments)
limiter = Limiter(
    key_func=get_remote_address,
    default_limits=[],  # Sem limite global
    storage_uri="memory://",  # Storage em mem√≥ria
)


# ============================================================================
# LIFESPAN EVENTS (startup/shutdown)
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Gerencia o ciclo de vida da aplica√ß√£o.
    
    Executado na inicializa√ß√£o e shutdown do servidor.
    √ötil para:
    - Inicializar conex√µes (DB, cache, etc)
    - Carregar modelos em mem√≥ria
    - Cleanup de recursos
    """
    # Startup - Logger j√° foi inicializado no m√≥dulo
    logger.info("üöÄ Iniciando microservi√ßo de extra√ß√£o de reuni√µes...")
    logger.info("‚úÖ Pronto para receber requisi√ß√µes")
    
    yield  # Aplica√ß√£o roda aqui
    
    # Shutdown
    logger.info("üõë Encerrando microservi√ßo...")


# ============================================================================
# INICIALIZA√á√ÉO DA APLICA√á√ÉO
# ============================================================================

app = FastAPI(
    title="Meeting Extractor API",
    description=(
        "Microservi√ßo para extra√ß√£o estruturada de informa√ß√µes de "
        "transcri√ß√µes de reuni√µes banc√°rias usando OpenAI API + LangChain"
    ),
    version="1.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
)

# ============================================================================
# CONFIGURA√á√ÉO DE M√âTRICAS PROMETHEUS
# ============================================================================

# Inicializa o instrumentador Prometheus
instrumentator = Instrumentator(
    should_group_status_codes=False,  # Mant√©m c√≥digos de status espec√≠ficos
    should_ignore_untemplated=True,   # Ignora rotas n√£o mapeadas
    should_respect_env_var=True,      # Respeita ENABLE_METRICS env var
    should_instrument_requests_inprogress=True,  # M√©tricas de requests em progresso
    excluded_handlers=["/metrics"],   # N√£o instrumenta o pr√≥prio endpoint de m√©tricas
    env_var_name="ENABLE_METRICS",    # Nome da vari√°vel de ambiente (padr√£o: True)
    inprogress_name="http_requests_inprogress",
    inprogress_labels=True,
)

print("üîß [DEBUG] Criando instrumentador Prometheus...")

# Instrumenta a aplica√ß√£o FastAPI
instrumentator.instrument(app)
print("‚úÖ [DEBUG] Instrumentador aplicado √† FastAPI!")

# Exp√µe o endpoint /metrics
instrumentator.expose(app, endpoint="/metrics", tags=["Monitoring"])
print("‚úÖ [DEBUG] Endpoint /metrics exposto!")

# ============================================================================
# CONFIGURA√á√ÉO DE RATE LIMITING
# ============================================================================

# Adiciona o limiter ao estado da aplica√ß√£o
app.state.limiter = limiter

# Adiciona exception handler padr√£o do SlowAPI
# (Ser√° sobrescrito pelo nosso handler customizado abaixo)
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)


# ============================================================================
# MIDDLEWARE PARA REQUEST_ID
# ============================================================================

@app.middleware("http")
async def add_request_id_and_metrics(request: Request, call_next):
    """
    Middleware que adiciona Request-ID e registra m√©tricas HTTP.
    
    Usado para correla√ß√£o de logs e debugging. Se o cliente j√° enviar
    um X-Request-ID, ele √© preservado; caso contr√°rio, um novo UUID √© gerado.
    
    Args:
        request: Requisi√ß√£o HTTP recebida
        call_next: Pr√≥xima fun√ß√£o na cadeia de middleware
    
    Returns:
        Response: Resposta HTTP com header X-Request-ID
    """
    import time
    
    request_id = request.headers.get("X-Request-ID", str(uuid.uuid4()))
    request.state.request_id = request_id
    
    # Captura in√≠cio da requisi√ß√£o
    start_time = time.time()
    
    try:
        response = await call_next(request)
        
        # Registra m√©tricas de sucesso
        record_http_request(
            method=request.method,
            endpoint=request.url.path,
            status_code=response.status_code
        )
        record_http_duration(
            method=request.method,
            endpoint=request.url.path,
            duration=time.time() - start_time
        )
        
        response.headers["X-Request-ID"] = request_id
        return response
        
    except Exception as e:
        # Registra m√©tricas de erro
        record_http_request(
            method=request.method,
            endpoint=request.url.path,
            status_code=500
        )
        record_http_duration(
            method=request.method,
            endpoint=request.url.path,
            duration=time.time() - start_time
        )
        raise


# ============================================================================
# EXCEPTION HANDLERS
# ============================================================================

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(
    request: Request, 
    exc: RequestValidationError
    ) -> JSONResponse:
    """
    Handler para erros de valida√ß√£o do Pydantic (422 Unprocessable Entity).
    
    Retorna mensagens de erro estruturadas e amig√°veis quando a valida√ß√£o
    do corpo da requisi√ß√£o falha.
    
    Args:
        request: Requisi√ß√£o HTTP que causou o erro
        exc: Exce√ß√£o de valida√ß√£o do Pydantic
    
    Returns:
        JSONResponse: Resposta 422 com detalhes dos erros de valida√ß√£o
    """
    request_id = getattr(request.state, "request_id", "-")
    
    # Serializa os erros de valida√ß√£o de forma segura
    errors = []
    for error in exc.errors():
        errors.append({
            "loc": error.get("loc", []),
            "msg": str(error.get("msg", "")),
            "type": error.get("type", ""),
        })
    
    logger.warning(
        f"[{request_id}] Validation error | "
        f"errors={errors}"
    )
    
    return JSONResponse(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        content={
            "error": "validation_error",
            "message": "Dados de entrada inv√°lidos",
            "details": errors,
            "request_id": request_id,
        }
    )


@app.exception_handler(RateLimitExceeded)
async def rate_limit_exception_handler(
    request: Request,
    exc: RateLimitExceeded
    ) -> JSONResponse:
    """
    Handler para erros de rate limiting (429 Too Many Requests).
    
    Retorna mensagem estruturada quando o cliente excede o limite de
    requisi√ß√µes por minuto, incluindo o header Retry-After.
    
    Args:
        request: Requisi√ß√£o HTTP que causou o erro
        exc: Exce√ß√£o de rate limit excedido
    
    Returns:
        JSONResponse: Resposta 429 com detalhes do limite e Retry-After header
    """
    request_id = getattr(request.state, "request_id", "-")
    client_ip = get_remote_address(request)
    
    # Obt√©m o limite configurado (padr√£o: 10/minute)
    rate_limit = os.getenv("RATE_LIMIT_PER_MINUTE", "10")
    
    # Registra m√©trica de rate limit excedido
    endpoint = request.url.path
    record_rate_limit_exceeded(endpoint)
    
    logger.warning(
        f"[{request_id}] Rate limit exceeded | "
        f"ip={client_ip} | "
        f"limit={rate_limit}/minute"
    )
    
    return JSONResponse(
        status_code=status.HTTP_429_TOO_MANY_REQUESTS,
        content={
            "error": "rate_limit_exceeded",
            "message": (
                "Voc√™ excedeu o limite de requisi√ß√µes. "
                "Tente novamente em alguns instantes."
            ),
            "limit": f"{rate_limit} requisi√ß√µes por minuto",
            "request_id": request_id,
        },
        headers={
            "Retry-After": "60"  # Segundos at√© poder tentar novamente
        }
    )


@app.exception_handler(Exception)
async def generic_exception_handler(
    request: Request,
    exc: Exception
    ) -> JSONResponse:
    """
    Handler gen√©rico para exce√ß√µes n√£o tratadas (500 Internal Server Error).
    
    Captura qualquer exce√ß√£o n√£o prevista e retorna uma resposta estruturada,
    evitando expor detalhes internos sens√≠veis ao cliente.
    
    Args:
        request: Requisi√ß√£o HTTP que causou o erro
        exc: Exce√ß√£o n√£o tratada
    
    Returns:
        JSONResponse: Resposta 500 com mensagem gen√©rica
    """
    request_id = getattr(request.state, "request_id", "-")
    
    logger.error(
        f"[{request_id}] Unhandled exception | "
        f"type={type(exc).__name__} | "
        f"error={str(exc)[:200]}"
    )
    
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "error": "internal_server_error",
            "message": "Erro interno do servidor",
            "request_id": request_id,
        }
    )


# ============================================================================
# ENDPOINTS
# ============================================================================

@app.get("/health", tags=["Health"])
async def health_check() -> Dict[str, str]:
    """
    Health check endpoint.
    
    Verifica se o servi√ßo est√° funcionando corretamente.
    √ötil para:
    - Load balancers
    - Kubernetes liveness/readiness probes
    - Monitoramento
    
    Returns:
        dict: Status do servi√ßo
    
    Example:
        ```bash
        curl http://localhost:8000/health
        # {"status": "healthy", "service": "meeting-extractor"}
        ```
    """
    return {
        "status": "healthy",
        "service": "meeting-extractor",
    }


@app.post(
    "/extract",
    response_model=ExtractedMeeting,
    status_code=status.HTTP_200_OK,
    tags=["Extraction"],
    summary="Extrai informa√ß√µes estruturadas de uma transcri√ß√£o",
    response_description="Informa√ß√µes estruturadas extra√≠das com sucesso"
    )
@limiter.limit("10/minute")
async def extract_meeting(
    request: Request,
    body: ExtractRequest # faz a valida√ß√£o pelo Pydantic do body
    ) -> ExtractedMeeting:
    """
    Extrai informa√ß√µes estruturadas de uma transcri√ß√£o de reuni√£o.
    
    Este endpoint recebe uma transcri√ß√£o de reuni√£o banc√°ria (em um de dois formatos)
    e retorna um JSON estruturado com informa√ß√µes extra√≠das usando OpenAI API.
    
    **Formatos de entrada aceitos:**
    
    1. **Formato expl√≠cito** (transcript + metadata opcional):
       ```json
       {
         "transcript": "Cliente: Bom dia... Banker: Ol√°...",
         "metadata": {
           "meeting_id": "MTG123",
           "customer_id": "CUST456",
           "customer_name": "ACME S.A.",
           "banker_id": "BKR789",
           "banker_name": "Pedro Falc√£o",
           "meet_type": "Primeira Reuni√£o",
           "meet_date": "2025-09-10T14:30:00Z"
         }
       }
       ```
    
    2. **Formato bruto** (raw_meeting, vindo de sistemas upstream):
       ```json
       {
         "raw_meeting": {
           "meet_id": "MTG123",
           "customer_id": "CUST456",
           "customer_name": "ACME S.A.",
           "banker_id": "BKR789",
           "banker_name": "Pedro Falc√£o",
           "meet_date": "2025-09-10T14:30:00Z",
           "meet_type": "Primeira Reuni√£o",
           "meet_transcription": "Cliente: Bom dia..."
         }
       }
       ```
    
    **Observa√ß√µes importantes:**
    
    - Metadados s√£o **opcionais** no input, mas **obrigat√≥rios** no output
    - Se metadados n√£o forem fornecidos, o LLM tentar√° extra√≠-los da transcri√ß√£o
    - Se metadados forem fornecidos, eles t√™m **prioridade absoluta** sobre a transcri√ß√£o
    - A chave de idempot√™ncia √© calculada automaticamente (SHA-256) quando poss√≠vel
    
    **Resili√™ncia:**
    
    - Timeout: 30 segundos m√°ximo por chamada √† OpenAI
    - Retries: at√© 3 tentativas com backoff exponencial (0.5s, 1s, 2s)
    - Repair: 1 tentativa de reparo autom√°tico se valida√ß√£o Pydantic falhar
    
    **Seguran√ßa:**
    
    - Logs n√£o cont√™m transcri√ß√µes completas (apenas primeiros 300 chars)
    - Request ID √∫nico para correla√ß√£o de logs
    - Sem exposi√ß√£o de detalhes internos em erros
    
    Args:
        request: Objeto Request do FastAPI (injetado automaticamente)
        body: Corpo da requisi√ß√£o validado pelo Pydantic
    
    Returns:
        ExtractedMeeting: JSON estruturado com informa√ß√µes extra√≠das
    
    Raises:
        422: Erro de valida√ß√£o no input
        502: Erro na chamada √† OpenAI (timeout, rate limit, etc)
        500: Erro interno n√£o esperado
    
    Example:
        ```bash
        curl -X POST http://localhost:8000/extract \\
          -H "Content-Type: application/json" \\
          -d '{
            "transcript": "Cliente: Preciso de um empr√©stimo...",
            "metadata": {
              "meeting_id": "MTG001",
              "customer_id": "CUST001"
            }
          }'
        ```
    """
    import time
    start_time = time.time()
    http_start_time = time.time()  # Timer separado para m√©tricas HTTP
    request_id = request.state.request_id
    
    # Log in√≠cio - Identifica formato de entrada
    if body.raw_meeting:
        input_format = "raw_meeting"
        has_metadata = True
    elif body.metadata:
        input_format = "transcript+metadata"
        has_metadata = True
    else:
        input_format = "transcript_only"
        has_metadata = False
    
    logger.info(
        f"[INCOMING] [{request_id}] POST /extract received | "
        f"format={input_format} | "
        f"has_metadata={has_metadata}"
    )
    
    try:
        # 1. Normalizar input (converte ambos os formatos para NormalizedInput)
        logger.info(f"[{request_id}] Iniciando normaliza√ß√£o...")
        normalized = body.to_normalized()
        
        # Registra m√©trica do tamanho da transcri√ß√£o
        transcript_size = len(normalized.transcript.encode('utf-8'))
        record_transcript_size(transcript_size)
        
        # Log detalhes da normaliza√ß√£o
        metadata_fields = sum([
            normalized.meeting_id is not None,
            normalized.customer_id is not None,
            normalized.customer_name is not None,
            normalized.banker_id is not None,
            normalized.banker_name is not None,
            normalized.meet_type is not None,
            normalized.meet_date is not None
        ])
        
        logger.info(
            f"[{request_id}] Normaliza√ß√£o conclu√≠da | "
            f"transcript_len={len(normalized.transcript)} chars | "
            f"transcript_words={len(normalized.transcript.split())} words | "
            f"metadata_fields={metadata_fields}/7 | "
            f"meeting_id={normalized.meeting_id or 'will_extract'} | "
            f"customer_id={normalized.customer_id or 'will_extract'}"
        )
        
        # 2. Chamar o extractor (LangChain + OpenAI)
        # Timer para dura√ß√£o da extra√ß√£o
        extraction_start = time.time()
        
        extracted = await extract_meeting_chain(
            normalized=normalized,
            request_id=request_id
        )
        
        # Registra m√©trica de dura√ß√£o da extra√ß√£o
        extraction_duration = time.time() - extraction_start
        extraction_duration_seconds.observe(extraction_duration)
        
        # 3. Log sucesso com dura√ß√£o
        duration = time.time() - start_time
        logger.info(
            f"[{request_id}] Extra√ß√£o conclu√≠da com sucesso | "
            f"duration={duration:.2f}s | "
            f"meeting_id={extracted.meeting_id} | "
            f"summary_words={len(extracted.summary.split())} | "
            f"key_points={len(extracted.key_points)} | "
            f"action_items={len(extracted.action_items)} | "
            f"topics={len(extracted.topics)} | "
            f"idempotency_key={extracted.idempotency_key[:16]}..."
        )
        
        # Registra m√©trica de reuni√£o extra√≠da com sucesso
        source = "raw_meeting" if body.raw_meeting else "transcript"
        meeting_type = extracted.meet_type or "Unknown"
        record_meeting_extracted(source, meeting_type)
        
        # Registra m√©trica de dura√ß√£o HTTP total
        http_duration = time.time() - http_start_time
        record_http_duration("POST", "/extract", http_duration)
        
        return extracted
    
    except (RateLimitError, APITimeoutError, APIError) as e:
        # Erros de comunica√ß√£o com OpenAI API ‚Üí 502 Bad Gateway
        logger.error(
            f"[{request_id}] Erro de comunica√ß√£o com OpenAI API | "
            f"type={type(e).__name__} | "
            f"error={str(e)[:200]}"
        )
        
        # Registra m√©trica de erro 502
        record_api_error("openai_communication_error", 502)
        
        return JSONResponse(
            status_code=status.HTTP_502_BAD_GATEWAY,
            content={
                "error": "openai_communication_error",
                "message": (
                    "Erro ao comunicar com OpenAI API "
                    "(timeout, rate limit ou indisponibilidade). "
                    "Tente novamente em alguns instantes."
                ),
                "error_type": type(e).__name__,
                "request_id": request_id,
            }
        )
    
    except ValidationError as e:
        # Erro de valida√ß√£o: OpenAI retornou dados inv√°lidos ‚Üí 502 Bad Gateway
        # Este √© um problema do servi√ßo externo (OpenAI), n√£o interno
        logger.error(
            f"[{request_id}] OpenAI retornou dados inv√°lidos ap√≥s repair | "
            f"errors={e.errors()}"
        )
        
        # Registra m√©trica de erro 502
        record_api_error("openai_invalid_response", 502)
        
        return JSONResponse(
            status_code=status.HTTP_502_BAD_GATEWAY,
            content={
                "error": "openai_invalid_response",
                "message": (
                    "OpenAI retornou dados inv√°lidos ou incompletos. "
                    "Tente novamente ou verifique se a transcri√ß√£o est√° leg√≠vel."
                ),
                "request_id": request_id,
            }
        )
    
    except Exception as e:
        # Qualquer outro erro n√£o previsto
        logger.error(
            f"[{request_id}] Erro inesperado | "
            f"type={type(e).__name__} | "
            f"error={str(e)[:200]}"
        )
        
        # Registra m√©trica de erro 500
        record_api_error("internal_error", 500)
        
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={
                "error": "internal_error",
                "message": "Erro interno ao processar a requisi√ß√£o",
                "request_id": request_id,
            }
        )



# ENDPOINT PARA DEBUG
@app.get("/metrics", tags=["Debug"])
async def debug_metrics():
    """Endpoint para testar m√©tricas"""
    from prometheus_client import generate_latest, CONTENT_TYPE_LATEST
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)


# ============================================================================
# ENTRYPOINT (para desenvolvimento)
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    # Roda o servidor em modo de desenvolvimento
    # Para produ√ß√£o, use: uvicorn app.main:app --host 0.0.0.0 --port 8000
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # Hot reload em desenvolvimento
        log_level="info",
    )

